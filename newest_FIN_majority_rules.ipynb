{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "newest_FIN_majority_rules.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install texthero"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQFbkoQipSxl",
        "outputId": "11c355cb-4141-4365-e634-d768c8c94395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: texthero in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: unidecode>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.3.4)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.2.2)\n",
            "Requirement already satisfied: wordcloud>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.21.6)\n",
            "Requirement already satisfied: nltk>=3.3 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.7)\n",
            "Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.7/dist-packages (from texthero) (4.64.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.3.5)\n",
            "Requirement already satisfied: plotly>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (5.5.0)\n",
            "Requirement already satisfied: gensim<4.0,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.6.0)\n",
            "Requirement already satisfied: spacy<3.0.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (2.2.4)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0,>=3.6.0->texthero) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0,>=3.6.0->texthero) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0,>=3.6.0->texthero) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.0->texthero) (4.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero) (2022.4.24)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.2->texthero) (2022.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.2.0->texthero) (8.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->texthero) (3.1.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (0.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (3.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (2.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2.10)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud>=1.5.0->texthero) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from dateutil.parser import parse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "import seaborn as sns\n",
        "sns.set_context(\"paper\", font_scale=1.3)\n",
        "sns.set_style('white')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from time import time\n",
        "import matplotlib.ticker as tkr\n",
        "from scipy import stats\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn import preprocessing\n",
        "from statsmodels.tsa.stattools import pacf\n",
        "%matplotlib inline\n",
        "import math\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import *\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from keras.callbacks import EarlyStopping\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "import time\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "import datetime\n",
        "from math import log, sqrt, pi, exp\n",
        "from scipy.stats import norm\n",
        "from datetime import datetime, date, timedelta\n",
        "from pandas import DataFrame\n",
        "import pandas as pd\n",
        "from bs4.element import DEFAULT_OUTPUT_ENCODING\n",
        "import re\n",
        "from gensim import corpora, models, similarities\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "# !{sys.executable} -m spacy download en\n",
        "import re, numpy as np, pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "import gensim, spacy, logging, warnings\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import  simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer, PorterStemmer\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from textblob import TextBlob\n",
        "import os\n",
        "import tweepy as tw\n",
        "import pandas as pd\n",
        "import re, numpy as np, pandas as pd\n",
        "from pprint import pprint\n",
        "from random import randint\n",
        "from time import sleep\n",
        "\n",
        "import gensim, spacy, logging, warnings\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import  simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer, PorterStemmer\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from textblob import TextBlob\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.corpus import stopwords\n"
      ],
      "metadata": {
        "id": "xHp8Q9O-bM4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWYlwlQ41OTc"
      },
      "outputs": [],
      "source": [
        "#ONLY RUN IF YOU WANT TO TRAIN/LABEL MORE TWEETS\n",
        "consumer_key= '7d7PKS74mTCa5EYGc6lw5KHyH'\n",
        "consumer_secret= 'FG2d31TVlPaR7zTedvsQUX9vkC5c4tInorAOPIdJ0nMNT2GqmP'\n",
        "access_token= '1343573569796767745-TDUJmh3IEyPIY390WkW1N10b9uBPZG'\n",
        "access_token_secret= '1PQ1MuLQtm82v6ML9ks908J75xvppFFkn1kH3cd4yLTyA'\n",
        "\n",
        "\n",
        "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "\n",
        "time_since = '2022-04-10'\n",
        "date_until = '2022-04-20'\n",
        "search = 'bucks&-1.5'\n",
        "search = search + \" -filter:retweets\"\n",
        "\n",
        "num_tweets = 3000\n",
        "tweets = tw.Cursor(api.search,\n",
        "                    q=search,\n",
        "                    since = time_since,\n",
        "                    until = date_until,\n",
        "                    lang=\"en\").items(num_tweets)\n",
        "\n",
        "\n",
        "all_tweets = [[tweet.text, tweet.created_at.date(),tweet.retweet_count,tweet.favorite_count] for tweet in tweets]\n",
        "\n",
        "df = pd.DataFrame(all_tweets)\n",
        "iii = 0 \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if iii == 0:\n",
        "  df.to_csv('bucks_train.csv')\n",
        "  iii = iii+1\n",
        "else:\n",
        "  print('no dataset to save')"
      ],
      "metadata": {
        "id": "L5w6Z81YeTAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e031aaa1-e7b6-4e2f-ed4a-49887365f133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no dataset to save\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cel = pd.read_csv('/content/bucks_train.csv')\n",
        "print('BUCKS - vs bulls')\n",
        "cell = pd.DataFrame()\n",
        "cell['text'] = cel['0']\n",
        "\n",
        "\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use','www','https','com','fags','string','sleep','apnea','cpap','co','machine','get','getting'])\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) \n",
        "              if word not in stop_words] for doc in texts]\n",
        "data = cell.text.values.tolist()\n",
        "data_words = list(sent_to_words(data))\n",
        "data_wordss = remove_stopwords(data_words)\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------------------\n",
        "def sent_to_words(sentences):\n",
        "    for sent in sentences:\n",
        "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
        "        yield(sent)\n",
        "\n",
        "bigram = gensim.models.Phrases(data_wordss, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_wordss], threshold=100)  \n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
        "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "    texts = [bigram_mod[doc] for doc in texts]\n",
        "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
        "    return texts_out\n",
        "data_ready = process_words(data_words)  \n",
        "data_ready\n",
        "\n",
        "cell['text'][0]\n",
        "celll =[]\n",
        "import re\n",
        "\n",
        "for sfw in range(len(cell['text'])):\n",
        "  tr = re.sub(\"[^0-9]\", \",\", cell['text'][sfw]).split(',')\n",
        "  gg = []\n",
        "  for xc in range(len(tr)):\n",
        "    if len(tr[xc])==0:\n",
        "      faf = 0\n",
        "    else:\n",
        "      gg.append(tr[xc])\n",
        "  celll.append(gg)\n",
        "\n",
        "\n",
        "len(celll)\n",
        "celtics = pd.DataFrame()\n",
        "celtics['text'] = cell['text']\n",
        "celtics = pd.merge(celtics.reset_index(), pd.DataFrame(data_words).reset_index(), on = 'index').drop(columns = ['index'])\n",
        "celtics = pd.merge(celtics.reset_index(), pd.DataFrame(celll).reset_index(), on = 'index').drop(columns = 'index')\n",
        "celtics['target'] = cel['Unnamed: 0'].fillna(0)\n",
        "print('input search term')\n",
        "search = input().lower()\n",
        "print('input the opposing team')\n",
        "other = input().lower()\n",
        "print('enter the nickname of the search term')\n",
        "nickname = input().lower()\n",
        "print('enter the nickname of the opp term')\n",
        "nickname1 = input().lower()\n",
        "print('input the search teams line')\n",
        "line_search = float(input())\n",
        "print('input the opps team line')\n",
        "line_op = float(input())\n",
        "\n",
        "cc = []\n",
        "for x in range(len(celtics['target'])):\n",
        "  cc.append(nickname)\n",
        "celtics['nickname_search'] = cc\n",
        "\n",
        "cc = []\n",
        "for x in range(len(celtics['target'])):\n",
        "  cc.append(search)\n",
        "celtics['team'] = cc\n",
        "\n",
        "cc = []\n",
        "for x in range(len(celtics['target'])):\n",
        "  cc.append(other)\n",
        "celtics['op_team'] = cc\n",
        "\n",
        "cc = []\n",
        "for x in range(len(celtics['target'])):\n",
        "  cc.append(nickname1)\n",
        "celtics['nickname_op'] = cc\n",
        "cc = []\n",
        "for x in range(len(celtics['target'])):\n",
        "  cc.append(line_search)\n",
        "celtics['search_line'] = cc\n",
        "cc = []\n",
        "for x in range(len(celtics['target'])):\n",
        "  cc.append(line_op)\n",
        "celtics['op_line'] = cc\n",
        "\n",
        "df111 = celtics\n",
        "\n",
        "print('search again? (yes/no)')\n",
        "sss = input().lower()\n",
        "\n",
        "if sss == 'no':\n",
        "  hgh = 2\n",
        "else:\n",
        "  cel = pd.read_csv('/content/bulls_train.csv')\n",
        "  print('BULLS - vs bucks')\n",
        "\n",
        "  cell = pd.DataFrame()\n",
        "  cell['text'] = cel['0']\n",
        "\n",
        "\n",
        "  import gensim\n",
        "  from gensim.utils import simple_preprocess\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  from nltk.corpus import stopwords\n",
        "  stop_words = stopwords.words('english')\n",
        "  stop_words.extend(['from', 'subject', 're', 'edu', 'use','www','https','com','fags','string','sleep','apnea','cpap','co','machine','get','getting'])\n",
        "  def sent_to_words(sentences):\n",
        "      for sentence in sentences:\n",
        "          yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "  def remove_stopwords(texts):\n",
        "      return [[word for word in simple_preprocess(str(doc)) \n",
        "                if word not in stop_words] for doc in texts]\n",
        "  data = cell.text.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  data_wordss = remove_stopwords(data_words)\n",
        "\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "  def sent_to_words(sentences):\n",
        "      for sent in sentences:\n",
        "          sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
        "          yield(sent)\n",
        "\n",
        "  bigram = gensim.models.Phrases(data_wordss, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_wordss], threshold=100)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "  def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "      \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
        "      texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "      texts = [bigram_mod[doc] for doc in texts]\n",
        "      texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "      texts_out = []\n",
        "      for sent in texts:\n",
        "          doc = nlp(\" \".join(sent)) \n",
        "          texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "      texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
        "      return texts_out\n",
        "  data_ready = process_words(data_words)  \n",
        "  data_ready\n",
        "\n",
        "  cell['text'][0]\n",
        "  celll =[]\n",
        "  import re\n",
        "\n",
        "  for sfw in range(len(cell['text'])):\n",
        "    tr = re.sub(\"[^0-9]\", \",\", cell['text'][sfw]).split(',')\n",
        "    gg = []\n",
        "    for xc in range(len(tr)):\n",
        "      if len(tr[xc])==0:\n",
        "        faf = 0\n",
        "      else:\n",
        "        gg.append(tr[xc])\n",
        "    celll.append(gg)\n",
        "\n",
        "\n",
        "  len(celll)\n",
        "  celtics = pd.DataFrame()\n",
        "  celtics['text'] = cell['text']\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(data_words).reset_index(), on = 'index').drop(columns = ['index'])\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(celll).reset_index(), on = 'index').drop(columns = 'index')\n",
        "  celtics['target'] = cel['Unnamed: 0'].fillna(0)\n",
        "  print('input search term')\n",
        "  search = input().lower()\n",
        "  print('input the opposing team')\n",
        "  other = input().lower()\n",
        "  ('enter the nickname of the search term')\n",
        "  nickname = input().lower()\n",
        "  ('enter the nickname of the opp term')\n",
        "  nickname1 = input().lower()\n",
        "  print('input the search teams line')\n",
        "  line_search = input().lower()\n",
        "  print('input the opps team line')\n",
        "  line_op = input().lower()\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(nickname)\n",
        "  celtics['nickname_search'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(search)\n",
        "  celtics['team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(other)\n",
        "  celtics['op_team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(nickname1)\n",
        "  celtics['nickname_op'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(line_search)\n",
        "  celtics['search_line'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(line_op)\n",
        "  celtics['op_line'] = cc\n",
        "  df222 = celtics\n",
        "  df_fin = df111.append(df222)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('length of nets targets = ' +str(len(df_fin[df_fin['target']==1])))\n",
        "print('length of celtics targets = ' + str(len(df_fin[df_fin['target']==2])))\n",
        "print('length of nan targets = ' +str(len(df_fin[df_fin['target']==0])))\n",
        "\n",
        "\n",
        "if sss == 'no':\n",
        "  hgh = 2\n",
        "else:\n",
        "  cel = pd.read_csv('/content/celtics_train.csv')\n",
        "  print('CELTICS - vs nets')\n",
        "\n",
        "\n",
        "  cell = pd.DataFrame()\n",
        "  cell['text'] = cel['0']\n",
        "\n",
        "\n",
        "  import gensim\n",
        "  from gensim.utils import simple_preprocess\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  from nltk.corpus import stopwords\n",
        "  stop_words = stopwords.words('english')\n",
        "  stop_words.extend(['from', 'subject', 're', 'edu', 'use','www','https','com','fags','string','sleep','apnea','cpap','co','machine','get','getting'])\n",
        "  def sent_to_words(sentences):\n",
        "      for sentence in sentences:\n",
        "          yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "  def remove_stopwords(texts):\n",
        "      return [[word for word in simple_preprocess(str(doc)) \n",
        "                if word not in stop_words] for doc in texts]\n",
        "  data = cell.text.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  data_wordss = remove_stopwords(data_words)\n",
        "\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "  def sent_to_words(sentences):\n",
        "      for sent in sentences:\n",
        "          sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
        "          yield(sent)\n",
        "\n",
        "  bigram = gensim.models.Phrases(data_wordss, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_wordss], threshold=100)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "  def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "      \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
        "      texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "      texts = [bigram_mod[doc] for doc in texts]\n",
        "      texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "      texts_out = []\n",
        "      for sent in texts:\n",
        "          doc = nlp(\" \".join(sent)) \n",
        "          texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "      texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
        "      return texts_out\n",
        "  data_ready = process_words(data_words)  \n",
        "  data_ready\n",
        "\n",
        "  cell['text'][0]\n",
        "  celll =[]\n",
        "  import re\n",
        "\n",
        "  for sfw in range(len(cell['text'])):\n",
        "    tr = re.sub(\"[^0-9]\", \",\", cell['text'][sfw]).split(',')\n",
        "    gg = []\n",
        "    for xc in range(len(tr)):\n",
        "      if len(tr[xc])==0:\n",
        "        faf = 0\n",
        "      else:\n",
        "        gg.append(tr[xc])\n",
        "    celll.append(gg)\n",
        "\n",
        "\n",
        "  len(celll)\n",
        "  celtics = pd.DataFrame()\n",
        "  celtics['text'] = cell['text']\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(data_words).reset_index(), on = 'index').drop(columns = ['index'])\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(celll).reset_index(), on = 'index').drop(columns = 'index')\n",
        "  celtics['target'] = cel['Unnamed: 0'].fillna(0)\n",
        "  print('input search term')\n",
        "  search = input().lower()\n",
        "  print('input the opposing team')\n",
        "  other = input().lower()\n",
        "  ('enter the nickname of the search term')\n",
        "  nickname = input().lower()\n",
        "  ('enter the nickname of the opp term')\n",
        "  nickname1 = input().lower()\n",
        "  print('input the search teams line')\n",
        "  line_search = input().lower()\n",
        "  print('input the opps team line')\n",
        "  line_op = input().lower()\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(nickname)\n",
        "  celtics['nickname_search'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(search)\n",
        "  celtics['team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(other)\n",
        "  celtics['op_team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(nickname1)\n",
        "  celtics['nickname_op'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(line_search)\n",
        "  celtics['search_line'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(line_op)\n",
        "  celtics['op_line'] = cc\n",
        "  df222 = celtics\n",
        "  df_fin = df_fin.append(df222)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('length of nets targets = ' +str(len(df_fin[df_fin['target']==1])))\n",
        "print('length of celtics targets = ' + str(len(df_fin[df_fin['target']==2])))\n",
        "print('length of nan targets = ' +str(len(df_fin[df_fin['target']==0])))\n",
        "\n",
        "if sss == 'no':\n",
        "  hgh = 2\n",
        "else:\n",
        "  cel = pd.read_csv('/content/netss_train.csv')\n",
        "  print('NETS - vs celtics')\n",
        "  cell = pd.DataFrame()\n",
        "  cell['text'] = cel['0']\n",
        "\n",
        "\n",
        "  import gensim\n",
        "  from gensim.utils import simple_preprocess\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  from nltk.corpus import stopwords\n",
        "  stop_words = stopwords.words('english')\n",
        "  stop_words.extend(['from', 'subject', 're', 'edu', 'use','www','https','com','fags','string','sleep','apnea','cpap','co','machine','get','getting'])\n",
        "  def sent_to_words(sentences):\n",
        "      for sentence in sentences:\n",
        "          yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "  def remove_stopwords(texts):\n",
        "      return [[word for word in simple_preprocess(str(doc)) \n",
        "                if word not in stop_words] for doc in texts]\n",
        "  data = cell.text.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  data_wordss = remove_stopwords(data_words)\n",
        "\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "  def sent_to_words(sentences):\n",
        "      for sent in sentences:\n",
        "          sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
        "          yield(sent)\n",
        "\n",
        "  bigram = gensim.models.Phrases(data_wordss, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_wordss], threshold=100)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "  def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "      \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
        "      texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "      texts = [bigram_mod[doc] for doc in texts]\n",
        "      texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "      texts_out = []\n",
        "      for sent in texts:\n",
        "          doc = nlp(\" \".join(sent)) \n",
        "          texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "      texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
        "      return texts_out\n",
        "  data_ready = process_words(data_words)  \n",
        "  data_ready\n",
        "\n",
        "  cell['text'][0]\n",
        "  celll =[]\n",
        "  import re\n",
        "\n",
        "  for sfw in range(len(cell['text'])):\n",
        "    tr = re.sub(\"[^0-9]\", \",\", cell['text'][sfw]).split(',')\n",
        "    gg = []\n",
        "    for xc in range(len(tr)):\n",
        "      if len(tr[xc])==0:\n",
        "        faf = 0\n",
        "      else:\n",
        "        gg.append(tr[xc])\n",
        "    celll.append(gg)\n",
        "\n",
        "\n",
        "  len(celll)\n",
        "  celtics = pd.DataFrame()\n",
        "  celtics['text'] = cell['text']\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(data_words).reset_index(), on = 'index').drop(columns = ['index'])\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(celll).reset_index(), on = 'index').drop(columns = 'index')\n",
        "  celtics['target'] = cel['Unnamed: 0'].fillna(0)\n",
        "  print('input search term')\n",
        "  search = input().lower()\n",
        "  print('input the opposing team')\n",
        "  other = input().lower()\n",
        "  ('enter the nickname of the search term')\n",
        "  nickname = input().lower()\n",
        "  ('enter the nickname of the opp term')\n",
        "  nickname1 = input().lower()\n",
        "  print('input the search teams line')\n",
        "  line_search = input().lower()\n",
        "  print('input the opps team line')\n",
        "  line_op = input().lower()\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(nickname)\n",
        "  celtics['nickname_search'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(search)\n",
        "  celtics['team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(other)\n",
        "  celtics['op_team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(nickname1)\n",
        "  celtics['nickname_op'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(line_search)\n",
        "  celtics['search_line'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(line_op)\n",
        "  celtics['op_line'] = cc\n",
        "  df222 = celtics\n",
        "  df_fin = df_fin.append(df222)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('length of nets targets = ' +str(len(df_fin[df_fin['target']==1])))\n",
        "print('length of celtics targets = ' + str(len(df_fin[df_fin['target']==2])))\n",
        "print('length of nan targets = ' +str(len(df_fin[df_fin['target']==0])))\n",
        "\n",
        "if sss == 'no':\n",
        "  hgh = 2\n",
        "else:\n",
        "  cel = pd.read_csv('/content/nuggets_train.csv')\n",
        "  print('NUGGETS - vs warriors')\n",
        "\n",
        "  cell = pd.DataFrame()\n",
        "  cell['text'] = cel['0']\n",
        "\n",
        "\n",
        "  import gensim\n",
        "  from gensim.utils import simple_preprocess\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  from nltk.corpus import stopwords\n",
        "  stop_words = stopwords.words('english')\n",
        "  stop_words.extend(['from', 'subject', 're', 'edu', 'use','www','https','com','fags','string','sleep','apnea','cpap','co','machine','get','getting'])\n",
        "  def sent_to_words(sentences):\n",
        "      for sentence in sentences:\n",
        "          yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "  def remove_stopwords(texts):\n",
        "      return [[word for word in simple_preprocess(str(doc)) \n",
        "                if word not in stop_words] for doc in texts]\n",
        "  data = cell.text.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  data_wordss = remove_stopwords(data_words)\n",
        "\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "  def sent_to_words(sentences):\n",
        "      for sent in sentences:\n",
        "          sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
        "          yield(sent)\n",
        "\n",
        "  bigram = gensim.models.Phrases(data_wordss, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_wordss], threshold=100)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "  def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "      \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
        "      texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "      texts = [bigram_mod[doc] for doc in texts]\n",
        "      texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "      texts_out = []\n",
        "      for sent in texts:\n",
        "          doc = nlp(\" \".join(sent)) \n",
        "          texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "      texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
        "      return texts_out\n",
        "  data_ready = process_words(data_words)  \n",
        "  data_ready\n",
        "\n",
        "  cell['text'][0]\n",
        "  celll =[]\n",
        "  import re\n",
        "\n",
        "  for sfw in range(len(cell['text'])):\n",
        "    tr = re.sub(\"[^0-9]\", \",\", cell['text'][sfw]).split(',')\n",
        "    gg = []\n",
        "    for xc in range(len(tr)):\n",
        "      if len(tr[xc])==0:\n",
        "        faf = 0\n",
        "      else:\n",
        "        gg.append(tr[xc])\n",
        "    celll.append(gg)\n",
        "\n",
        "\n",
        "  len(celll)\n",
        "  celtics = pd.DataFrame()\n",
        "  celtics['text'] = cell['text']\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(data_words).reset_index(), on = 'index').drop(columns = ['index'])\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(celll).reset_index(), on = 'index').drop(columns = 'index')\n",
        "  celtics['target'] = cel['Unnamed: 0'].fillna(0)\n",
        "  print('input search term')\n",
        "  search = input().lower()\n",
        "  print('input the opposing team')\n",
        "  other = input().lower()\n",
        "  ('enter the nickname of the search term')\n",
        "  nickname = input().lower()\n",
        "  ('enter the nickname of the opp term')\n",
        "  nickname1 = input().lower()\n",
        "  print('input the search teams line')\n",
        "  line_search = input().lower()\n",
        "  print('input the opps team line')\n",
        "  line_op = input().lower()\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(nickname)\n",
        "  celtics['nickname_search'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(search)\n",
        "  celtics['team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(other)\n",
        "  celtics['op_team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(nickname1)\n",
        "  celtics['nickname_op'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(line_search)\n",
        "  celtics['search_line'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(line_op)\n",
        "  celtics['op_line'] = cc\n",
        "  df222 = celtics\n",
        "  df_fin = df_fin.append(df222)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('length of nets targets = ' +str(len(df_fin[df_fin['target']==1])))\n",
        "print('length of celtics targets = ' + str(len(df_fin[df_fin['target']==2])))\n",
        "print('length of nan targets = ' +str(len(df_fin[df_fin['target']==0])))\n",
        "\n",
        "if sss == 'no':\n",
        "  hgh = 2\n",
        "else:\n",
        "  cel = pd.read_csv('/content/warriors_train.csv')\n",
        "  print('WARRIORS - vs nugs')\n",
        "\n",
        "\n",
        "  cell = pd.DataFrame()\n",
        "  cell['text'] = cel['0']\n",
        "\n",
        "\n",
        "  import gensim\n",
        "  from gensim.utils import simple_preprocess\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  from nltk.corpus import stopwords\n",
        "  stop_words = stopwords.words('english')\n",
        "  stop_words.extend(['from', 'subject', 're', 'edu', 'use','www','https','com','fags','string','sleep','apnea','cpap','co','machine','get','getting'])\n",
        "  def sent_to_words(sentences):\n",
        "      for sentence in sentences:\n",
        "          yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "  def remove_stopwords(texts):\n",
        "      return [[word for word in simple_preprocess(str(doc)) \n",
        "                if word not in stop_words] for doc in texts]\n",
        "  data = cell.text.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  data_wordss = remove_stopwords(data_words)\n",
        "\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "  def sent_to_words(sentences):\n",
        "      for sent in sentences:\n",
        "          sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
        "          yield(sent)\n",
        "\n",
        "  bigram = gensim.models.Phrases(data_wordss, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_wordss], threshold=100)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "  def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "      \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
        "      texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "      texts = [bigram_mod[doc] for doc in texts]\n",
        "      texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "      texts_out = []\n",
        "      for sent in texts:\n",
        "          doc = nlp(\" \".join(sent)) \n",
        "          texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "      texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
        "      return texts_out\n",
        "  data_ready = process_words(data_words)  \n",
        "\n",
        "  celll =[]\n",
        "  import re\n",
        "\n",
        "  for sfw in range(len(cell['text'])):\n",
        "    tr = re.sub(\"[^0-9]\", \",\", cell['text'][sfw]).split(',')\n",
        "    gg = []\n",
        "    for xc in range(len(tr)):\n",
        "      if len(tr[xc])==0:\n",
        "        faf = 0\n",
        "      else:\n",
        "        gg.append(tr[xc])\n",
        "    celll.append(gg)\n",
        "\n",
        "\n",
        "  len(celll)\n",
        "  celtics = pd.DataFrame()\n",
        "  celtics['text'] = cell['text']\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(data_words).reset_index(), on = 'index').drop(columns = ['index'])\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(celll).reset_index(), on = 'index').drop(columns = 'index')\n",
        "  celtics['target'] = cel['Unnamed: 0'].fillna(0)\n",
        "  print('input search term')\n",
        "  search = input().lower()\n",
        "  print('input the opposing team')\n",
        "  other = input().lower()\n",
        "  ('enter the nickname of the search term')\n",
        "  nickname = input().lower()\n",
        "  ('enter the nickname of the opp term')\n",
        "  nickname1 = input().lower()\n",
        "  print('input the search teams line')\n",
        "  line_search = input().lower()\n",
        "  print('input the opps team line')\n",
        "  line_op = input().lower()\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(nickname)\n",
        "  celtics['nickname_search'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(search)\n",
        "  celtics['team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(other)\n",
        "  celtics['op_team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(nickname1)\n",
        "  celtics['nickname_op'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(line_search)\n",
        "  celtics['search_line'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['target'])):\n",
        "    cc.append(line_op)\n",
        "  celtics['op_line'] = cc\n",
        "  df222 = celtics\n",
        "  df_fin = df_fin.append(df222)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('length of nets targets = ' +str(len(df_fin[df_fin['target']==1])))\n",
        "print('length of celtics targets = ' + str(len(df_fin[df_fin['target']==2])))\n",
        "print('length of nan targets = ' +str(len(df_fin[df_fin['target']==0])))\n",
        "df_fin.head(10)\n",
        "print('length of dataframe is: '+str(len(df_fin)))"
      ],
      "metadata": {
        "id": "__13kSAsiw-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5fddffe-5ff0-4819-fd28-b2a84dd146d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BUCKS - vs bulls\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input search term\n",
            "bucks\n",
            "input the opposing team\n",
            "bulls\n",
            "enter the nickname of the search term\n",
            "mlk\n",
            "enter the nickname of the opp term\n",
            "chicago\n",
            "input the search teams line\n",
            "-2.5\n",
            "input the opps team line\n",
            "+2.5\n",
            "search again? (yes/no)\n",
            "yes\n",
            "BULLS - vs bucks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input search term\n",
            "bulls\n",
            "input the opposing team\n",
            "bucks\n",
            "chicago\n",
            "mlk\n",
            "input the search teams line\n",
            "+2.5\n",
            "input the opps team line\n",
            "-2.5\n",
            "length of nets targets = 101\n",
            "length of celtics targets = 178\n",
            "length of nan targets = 1657\n",
            "CELTICS - vs nets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input search term\n",
            "celtics\n",
            "input the opposing team\n",
            "nets\n",
            "boston\n",
            "brooklyn\n",
            "input the search teams line\n",
            "-3.5\n",
            "input the opps team line\n",
            "+3.5\n",
            "length of nets targets = 102\n",
            "length of celtics targets = 179\n",
            "length of nan targets = 1658\n",
            "NETS - vs celtics\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input search term\n",
            "nets\n",
            "input the opposing team\n",
            "celtics\n",
            "brooklyn\n",
            "boston\n",
            "input the search teams line\n",
            "+3.5\n",
            "input the opps team line\n",
            "-3.5\n",
            "length of nets targets = 102\n",
            "length of celtics targets = 216\n",
            "length of nan targets = 2621\n",
            "NUGGETS - vs warriors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input search term\n",
            "nuggets\n",
            "input the opposing team\n",
            "warriors\n",
            "denver\n",
            "golden\n",
            "input the search teams line\n",
            "+2.5\n",
            "input the opps team line\n",
            "-2.5\n",
            "length of nets targets = 105\n",
            "length of celtics targets = 231\n",
            "length of nan targets = 3603\n",
            "WARRIORS - vs nugs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input search term\n",
            "warriors\n",
            "input the opposing team\n",
            "nuggets\n",
            "golden\n",
            "denver\n",
            "input the search teams line\n",
            "-2.5\n",
            "input the opps team line\n",
            "+2.5\n",
            "length of nets targets = 125\n",
            "length of celtics targets = 234\n",
            "length of nan targets = 4580\n",
            "length of dataframe is: 6453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.DataFrame()\n",
        "df_test = df_fin[df_fin['target']==0].sample(n = 340,replace = True)\n",
        "df_test1 = df_fin[df_fin['target']==1].sample(n =340,replace = True)\n",
        "df_test2 = df_fin[df_fin['target']==2].sample(n =340,replace = True)\n",
        "peices = (df_test, df_test1, df_test2)\n",
        "fff = pd.concat(peices, ignore_index = True)\n",
        "fff['text'].dropna()\n",
        "fff = fff.sample(n = 1000)\n",
        "\n",
        "fff['ttt'] = fff['0_x'].astype(str)+' '+fff['2_x'].astype(str)+' '+fff['3_x'].astype(str)+' '+fff['4_x'].astype(str)+' '+fff['5_x'].astype(str)+' '+fff['6_x'].astype(str)+' '+fff['7_x'].astype(str)+' '+fff['8_x'].astype(str)+' '+fff['9_x'].astype(str)+' '+fff['10_x'].astype(str)+' '+fff['11_x'].astype(str)+' '+fff['12_x'].astype(str)+' '+fff['13_x'].astype(str)+' '+fff['14_x'].astype(str)+' '+fff['15_x'].astype(str)+' '+fff['16_x'].astype(str)+' '+fff['17_x'].astype(str)+' '+fff['18_x'].astype(str)+' '+fff['19_x'].astype(str)+' '+fff['20_x'].astype(str)\n",
        "fff['target']\n",
        "fff['ttt'] = fff['ttt'].reset_index().drop(columns = 'index')\n",
        "fff = fff.reset_index().drop(columns = 'index')\n",
        "\n",
        "import texthero as hero\n",
        "from texthero import preprocessing\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "custom_pipeline = [preprocessing.fillna,\n",
        "                   preprocessing.lowercase,\n",
        "                   preprocessing.remove_whitespace,\n",
        "                   preprocessing.remove_diacritics,\n",
        "                   preprocessing.remove_brackets\n",
        "                  ]\n",
        "df = pd.DataFrame()\n",
        "df['clean_text'] = hero.clean(fff['ttt'] , custom_pipeline)\n",
        "df['clean_text'] = [n.replace('{','') for n in df['clean_text']]\n",
        "df['clean_text'] = [n.replace('}','') for n in df['clean_text']]\n",
        "df['clean_text'] = [n.replace('(','') for n in df['clean_text']]\n",
        "df['clean_text'] = [n.replace(')','') for n in df['clean_text']]\n",
        "\n",
        "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
        "import os\n",
        "from sklearn import svm\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "\n",
        "df['tfidf'] = (hero.tfidf(df['clean_text'], max_features=30000))\n",
        "card_docs = [TaggedDocument(doc.split(' '), [i]) \n",
        "             for i, doc in enumerate(df.clean_text)]\n",
        "model = Doc2Vec(vector_size=64, min_count=1, epochs = 20)\n",
        "model = Doc2Vec(vector_size=64, window=2, min_count=1, workers=8, epochs = 40)\n",
        "model.build_vocab(card_docs)\n",
        "model.train(card_docs, total_examples=model.corpus_count\n",
        "            , epochs=model.epochs)\n",
        "card2vec = [model.infer_vector((df['clean_text'][i].split(' '))) \n",
        "            for i in range(0,len(df['clean_text']))]\n",
        "dtv= np.array(card2vec).tolist()\n",
        "df['card2vec'] = dtv\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
        "embeddings = embed(df['clean_text'])\n",
        "use= np.array(embeddings).tolist()\n",
        "df['use'] = [v for v in use]\n",
        "df['tsnetfidf'] = hero.tsne(df['tfidf'])\n",
        "df['tsnec2v'] = hero.tsne(df['card2vec'])\n",
        "df['tsneuse'] = hero.tsne(df['use'])\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "from collections import Counter\n",
        "\n",
        "df['line'] = df['clean_text'].str.replace(',', '')\n",
        "df['line'] = df['clean_text'].str.replace('.', '')\n",
        "\n",
        "df['celtics'] = df['clean_text'].map(lambda x: x.count(\"celtics\"))\n",
        "df['nets'] = df['clean_text'].map(lambda x: x.count(\"nets\"))\n",
        "\n",
        "df['bucks'] = df['clean_text'].map(lambda x: x.count(\"bucks\"))\n",
        "df['bulls'] = df['clean_text'].map(lambda x: x.count(\"bulls\"))\n",
        "\n",
        "df['warriors'] = df['clean_text'].map(lambda x: x.count(\"warriors\"))\n",
        "df['nuggets'] = df['clean_text'].map(lambda x: x.count(\"nuggets\"))\n",
        "\n",
        "df['boston'] = df['clean_text'].map(lambda x: x.count(\"boston\"))\n",
        "df['brooklyn'] = df['clean_text'].map(lambda x: x.count(\"brooklyn\"))\n",
        "\n",
        "df['milwaukee'] = df['clean_text'].map(lambda x: x.count(\"milwaukee\"))\n",
        "df['chicago'] = df['clean_text'].map(lambda x: x.count(\"chicago\"))\n",
        "\n",
        "df['golden'] = df['clean_text'].map(lambda x: x.count(\"golden\"))\n",
        "df['denver'] = df['clean_text'].map(lambda x: x.count(\"denver\"))\n",
        "\n",
        "df['ml'] = df['clean_text'].map(lambda x: x.count(\"ml\"))\n",
        "\n",
        "df['+'] = df['clean_text'].map(lambda x: x.count(\"+\"))\n",
        "df['-'] = df['clean_text'].map(lambda x: x.count(\"-\"))\n",
        "\n",
        "df['s_line'] = fff['search_line'].reset_index().drop_duplicates('index').drop(columns = 'index')\n",
        "df['op_line'] = fff['op_line'].reset_index().drop_duplicates('index').drop(columns = 'index')\n",
        "df['target'] = fff['target'].reset_index().drop_duplicates('index').reset_index().drop(columns = ['level_0','index'])\n",
        "\n",
        "df['search_'] = fff['team'].map(lambda x: x.count(\"celtics\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "df['search1'] = fff['team'].map(lambda x: x.count(\"nets\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['search2'] = fff['team'].map(lambda x: x.count(\"nuggets\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['search3'] = fff['team'].map(lambda x: x.count(\"warriors\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['search4'] = fff['team'].map(lambda x: x.count(\"bulls\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['search5'] = fff['team'].map(lambda x: x.count(\"bucks\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "\n",
        "df['op_'] = fff['op_team'].map(lambda x: x.count(\"nets\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op1'] = fff['op_team'].map(lambda x: x.count(\"celtics\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op2'] = fff['op_team'].map(lambda x: x.count(\"warriors\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op3'] = fff['op_team'].map(lambda x: x.count(\"nuggets\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op4'] = fff['op_team'].map(lambda x: x.count(\"bulls\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op5'] = fff['op_team'].map(lambda x: x.count(\"bucks\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df = df.drop(columns = ['line','clean_text','tfidf','card2vec','tsnetfidf','tsnec2v'])\n",
        "\n",
        "holder = []\n",
        "holder1 = []\n",
        "for x in range(len(df['use'])):\n",
        "  holder.append(str(str(df['use'][1][0:30]).replace('[','').replace(']','')).split(','))\n",
        "for x in range(len(df['tsneuse'])):\n",
        "  holder1.append(str(str(df['use'][1][0:30]).replace('[','').replace(']','')).split(','))\n",
        "\n",
        "df = pd.merge(df.reset_index(),pd.DataFrame(holder).reset_index(),on = 'index').drop(columns = ['index','use','tsneuse'])\n",
        "df = pd.merge(df.reset_index(),pd.DataFrame(holder1).reset_index(),on = 'index').drop(columns = ['index'])\n",
        "df = pd.merge(df.reset_index(),pd.DataFrame(celll).reset_index().iloc[:,0:10],on = 'index').drop(columns = ['index']) \n",
        "\n"
      ],
      "metadata": {
        "id": "1-So__yQwu2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['target']\n",
        "x = df.drop(columns = 'target').fillna(0).astype(float)\n",
        "xxx = x\n",
        "yyy = y\n",
        "xx = x\n",
        "yy = y\n",
        "\n",
        "\n",
        "\n",
        "if 2>1:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "  clf=RandomForestClassifier(n_estimators=1000)\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_pred=clf.predict(X_test)\n",
        "  print('random forest score = '+str(metrics.accuracy_score(y_test, y_pred)))\n",
        "else:\n",
        "  print('no random forest')\n",
        "if 1>2:\n",
        "  xx, yy = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
        "\n",
        "  model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "  n_scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "else:\n",
        "  print('no logistic regression')\n",
        "if 2>1:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(xxx, yyy, test_size=0.2)\n",
        "  lr_list = [0.05]\n",
        "  for learning_rate in lr_list:\n",
        "      gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
        "      gb_clf.fit(X_train, y_train)\n",
        "      print(\"Learning rate: \", learning_rate)\n",
        "      print(\"Gradient Boosted Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
        "      print(\"Gradient Boosted Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))\n",
        "else:\n",
        "  print('no gradient boosted forests')\n",
        "if 2>1:\n",
        "  xgb_clf = XGBClassifier()\n",
        "  xgb_clf.fit(X_train, y_train)\n",
        "  score = xgb_clf.score(X_test, y_test)\n",
        "  print('XGB Score = '+str(score))\n",
        "else:\n",
        "  print('no xg boosted forest')\n",
        "\n",
        "clf.predict(x)\n",
        "resultz = pd.DataFrame()\n",
        "resultz = pd.DataFrame(clf.predict_proba(x))\n",
        "resultz['actual'] = y\n",
        "print(resultz.head(50))\n",
        "first = pd.DataFrame()\n",
        "second = pd.DataFrame()\n",
        "\n",
        "first = resultz[resultz[2]>=.75]\n",
        "second = resultz[resultz[1]>=.75]\n",
        "\n",
        "first"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2glLWdQcGKGg",
        "outputId": "262b31f0-ff1b-4597-fe77-1fcda6d5cd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random forest score = 0.6\n",
            "no logistic regression\n",
            "Learning rate:  0.05\n",
            "Gradient Boosted Accuracy score (training): 0.674\n",
            "Gradient Boosted Accuracy score (validation): 0.665\n",
            "XGB Score = 0.63\n",
            "        0      1      2  actual\n",
            "0  0.0700 0.0320 0.8980  2.0000\n",
            "1  0.6652 0.3168 0.0180  0.0000\n",
            "2  0.1405 0.7257 0.1338  1.0000\n",
            "3  0.0420 0.8940 0.0640  1.0000\n",
            "4  0.1380 0.0188 0.8432  2.0000\n",
            "5  0.9072 0.0070 0.0858  0.0000\n",
            "6  0.1340 0.8480 0.0180  1.0000\n",
            "7  0.8310 0.0150 0.1540  0.0000\n",
            "8  0.2630 0.7336 0.0034  1.0000\n",
            "9  0.8875 0.1105 0.0020  0.0000\n",
            "10 0.0400 0.0410 0.9190  2.0000\n",
            "11 0.8600 0.0000 0.1400  0.0000\n",
            "12 0.9553 0.0290 0.0157  0.0000\n",
            "13 0.0710 0.9150 0.0140  1.0000\n",
            "14 0.8440 0.0020 0.1540  0.0000\n",
            "15 0.0790 0.8677 0.0533  1.0000\n",
            "16 0.8790 0.0370 0.0840  0.0000\n",
            "17 0.4950 0.4875 0.0175  1.0000\n",
            "18 0.1000 0.0180 0.8820  2.0000\n",
            "19 0.0750 0.9064 0.0186  1.0000\n",
            "20 0.6350 0.1870 0.1780  0.0000\n",
            "21 0.0528 0.1666 0.7806  2.0000\n",
            "22 0.0920 0.8340 0.0740  1.0000\n",
            "23 0.0979 0.0499 0.8522  2.0000\n",
            "24 0.2070 0.1095 0.6835  2.0000\n",
            "25 0.3400 0.4427 0.2173  1.0000\n",
            "26 0.8801 0.0140 0.1059  0.0000\n",
            "27 0.1460 0.0220 0.8320  2.0000\n",
            "28 0.9460 0.0040 0.0500  0.0000\n",
            "29 0.9945 0.0010 0.0045  0.0000\n",
            "30 0.0780 0.8880 0.0340  1.0000\n",
            "31 0.1664 0.0035 0.8302  2.0000\n",
            "32 0.8835 0.0110 0.1055  0.0000\n",
            "33 0.0150 0.9770 0.0080  1.0000\n",
            "34 0.8410 0.1180 0.0410  0.0000\n",
            "35 0.1160 0.0110 0.8730  2.0000\n",
            "36 0.3121 0.6817 0.0062  1.0000\n",
            "37 0.8743 0.1247 0.0010  0.0000\n",
            "38 0.4050 0.5747 0.0202  0.0000\n",
            "39 0.1240 0.0260 0.8500  2.0000\n",
            "40 0.0884 0.7523 0.1594  1.0000\n",
            "41 0.9260 0.0030 0.0710  0.0000\n",
            "42 0.0660 0.2392 0.6948  2.0000\n",
            "43 0.0820 0.0180 0.9000  2.0000\n",
            "44 0.0129 0.9329 0.0542  1.0000\n",
            "45 0.1440 0.8100 0.0460  1.0000\n",
            "46 0.1230 0.8600 0.0170  1.0000\n",
            "47 0.8250 0.1670 0.0080  0.0000\n",
            "48 0.1460 0.0950 0.7590  1.0000\n",
            "49 0.0280 0.0110 0.9610  2.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0      1      2  actual\n",
              "0   0.0700 0.0320 0.8980  2.0000\n",
              "4   0.1380 0.0188 0.8432  2.0000\n",
              "10  0.0400 0.0410 0.9190  2.0000\n",
              "18  0.1000 0.0180 0.8820  2.0000\n",
              "21  0.0528 0.1666 0.7806  2.0000\n",
              "..     ...    ...    ...     ...\n",
              "977 0.0793 0.0146 0.9061  0.0000\n",
              "985 0.0450 0.0100 0.9450  2.0000\n",
              "991 0.0120 0.0660 0.9220  2.0000\n",
              "993 0.0130 0.0045 0.9825  2.0000\n",
              "995 0.0340 0.1930 0.7730  2.0000\n",
              "\n",
              "[222 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15451d65-20eb-4616-aed8-02900430563e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0700</td>\n",
              "      <td>0.0320</td>\n",
              "      <td>0.8980</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.1380</td>\n",
              "      <td>0.0188</td>\n",
              "      <td>0.8432</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0400</td>\n",
              "      <td>0.0410</td>\n",
              "      <td>0.9190</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.1000</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.8820</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.1666</td>\n",
              "      <td>0.7806</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>0.0793</td>\n",
              "      <td>0.0146</td>\n",
              "      <td>0.9061</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>0.0450</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.9450</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.9825</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0.0340</td>\n",
              "      <td>0.1930</td>\n",
              "      <td>0.7730</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>222 rows  4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15451d65-20eb-4616-aed8-02900430563e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15451d65-20eb-4616-aed8-02900430563e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15451d65-20eb-4616-aed8-02900430563e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**running the trained model on new datasets!**"
      ],
      "metadata": {
        "id": "vFp4VmjTMIFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "consumer_key= '7d7PKS74mTCa5EYGc6lw5KHyH'\n",
        "consumer_secret= 'FG2d31TVlPaR7zTedvsQUX9vkC5c4tInorAOPIdJ0nMNT2GqmP'\n",
        "access_token= '1343573569796767745-TDUJmh3IEyPIY390WkW1N10b9uBPZG'\n",
        "access_token_secret= '1PQ1MuLQtm82v6ML9ks908J75xvppFFkn1kH3cd4yLTyA'\n",
        "\n",
        "\n",
        "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "\n",
        "time_since = '2022-04-24'\n",
        "date_until = '2022-04-25'\n",
        "print('enter the teams you would like to search for')\n",
        "team = input().lower()\n",
        "search = team+'&+1.5'\n",
        "search = search + \" -filter:retweets\"\n",
        "\n",
        "num_tweets = 3000\n",
        "tweets = tw.Cursor(api.search,\n",
        "                    q=search,\n",
        "                    since = time_since,\n",
        "                    until = date_until,\n",
        "                    lang=\"en\").items(num_tweets)\n",
        "\n",
        "\n",
        "all_tweets = [[tweet.text, tweet.created_at.date(),tweet.retweet_count,tweet.favorite_count] for tweet in tweets]\n",
        "\n",
        "df = pd.DataFrame(all_tweets)\n",
        "iii = 0 \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMNg2RGGGO61",
        "outputId": "f36a2008-f9b8-410a-d277-0bb104340fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter the teams you would like to search for\n",
            "celtics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "\n",
        "time_since = '2022-04-24'\n",
        "date_until = '2022-04-25'\n",
        "print('enter opposing second team')\n",
        "team = input().lower()\n",
        "print('enter opposing team line line')\n",
        "line = input()\n",
        "search = team+'&'+line\n",
        "search = search + \" -filter:retweets\"\n",
        "\n",
        "num_tweets = 3000\n",
        "tweets = tw.Cursor(api.search,\n",
        "                    q=search,\n",
        "                    since = time_since,\n",
        "                    until = date_until,\n",
        "                    lang=\"en\").items(num_tweets)\n",
        "\n",
        "\n",
        "all_tweets = [[tweet.text, tweet.created_at.date(),tweet.retweet_count,tweet.favorite_count] for tweet in tweets]\n",
        "\n",
        "df1 = pd.DataFrame(all_tweets)\n",
        "iii = 0 \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hazz_sWFGPMX",
        "outputId": "d41c6243-5930-4aa7-a532-53d8f2267429"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter opposing second team\n",
            "nets\n",
            "enter opposing team line line\n",
            "-1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('bucks!')\n",
        "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "\n",
        "time_since = '2022-04-24'\n",
        "date_until = '2022-04-25'\n",
        "print('enter search team')\n",
        "team = input().lower()\n",
        "print('enter search team line line')\n",
        "line = input()\n",
        "search = team+'&'+line\n",
        "search = search + \" -filter:retweets\"\n",
        "\n",
        "num_tweets = 3000\n",
        "tweets = tw.Cursor(api.search,\n",
        "                    q=search,\n",
        "                    since = time_since,\n",
        "                    until = date_until,\n",
        "                    lang=\"en\").items(num_tweets)\n",
        "\n",
        "\n",
        "all_tweets = [[tweet.text, tweet.created_at.date(),tweet.retweet_count,tweet.favorite_count] for tweet in tweets]\n",
        "\n",
        "df_bucks = pd.DataFrame(all_tweets)\n",
        "iii = 0 \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONB6RI9eo0tV",
        "outputId": "61007a35-7fa5-4ab2-9aba-fd55a397550d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bucks!\n",
            "enter search team\n",
            "bucks\n",
            "enter search team line line\n",
            "-4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('bulls!')\n",
        "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "\n",
        "time_since = '2022-04-24'\n",
        "date_until = '2022-04-25'\n",
        "print('enter opposing team')\n",
        "team = input().lower()\n",
        "print('enter opposing team line')\n",
        "line = input()\n",
        "search = team+'&'+line\n",
        "search = search + \" -filter:retweets\"\n",
        "\n",
        "num_tweets = 3000\n",
        "tweets = tw.Cursor(api.search,\n",
        "                    q=search,\n",
        "                    since = time_since,\n",
        "                    until = date_until,\n",
        "                    lang=\"en\").items(num_tweets)\n",
        "\n",
        "\n",
        "all_tweets = [[tweet.text, tweet.created_at.date(),tweet.retweet_count,tweet.favorite_count] for tweet in tweets]\n",
        "\n",
        "df_bulls = pd.DataFrame(all_tweets)\n",
        "iii = 0 \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "445kbKr9o2dP",
        "outputId": "1ea8bf4b-10d3-42c9-94de-2e51f707f5cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bulls!\n",
            "enter opposing team\n",
            "bulls\n",
            "enter opposing team line\n",
            "+4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('warriors!')\n",
        "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "\n",
        "time_since = '2022-04-24'\n",
        "date_until = '2022-04-25'\n",
        "print('enter search team')\n",
        "team = input().lower()\n",
        "print('enter search line')\n",
        "line = input()\n",
        "search = team+'&'+line\n",
        "search = search + \" -filter:retweets\"\n",
        "\n",
        "num_tweets = 3000\n",
        "tweets = tw.Cursor(api.search,\n",
        "                    q=search,\n",
        "                    since = time_since,\n",
        "                    until = date_until,\n",
        "                    lang=\"en\").items(num_tweets)\n",
        "\n",
        "\n",
        "all_tweets = [[tweet.text, tweet.created_at.date(),tweet.retweet_count,tweet.favorite_count] for tweet in tweets]\n",
        "\n",
        "df_wars = pd.DataFrame(all_tweets)\n",
        "iii = 0 \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPv9IOALo29l",
        "outputId": "f8ea5122-e7c0-4d4c-f13b-dd49a5e5c30f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "warriors!\n",
            "enter search team\n",
            "warriors\n",
            "enter search line\n",
            "-4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('nuggets!')\n",
        "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "\n",
        "time_since = '2022-04-24'\n",
        "date_until = '2022-04-25'\n",
        "print('enter opposing  team')\n",
        "team = input().lower()\n",
        "print('enter opposing team line')\n",
        "line = input()\n",
        "search = team+'&'+line\n",
        "search = search + \" -filter:retweets\"\n",
        "\n",
        "num_tweets = 3000\n",
        "tweets = tw.Cursor(api.search,\n",
        "                    q=search,\n",
        "                    since = time_since,\n",
        "                    until = date_until,\n",
        "                    lang=\"en\").items(num_tweets)\n",
        "\n",
        "\n",
        "all_tweets = [[tweet.text, tweet.created_at.date(),tweet.retweet_count,tweet.favorite_count] for tweet in tweets]\n",
        "\n",
        "df_nugs = pd.DataFrame(all_tweets)\n",
        "iii = 0 \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs5A3C_1o3pZ",
        "outputId": "7b88578e-59be-4649-8567-1bd368c955fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nuggets!\n",
            "enter opposing  team\n",
            "nuggets\n",
            "enter opposing team line\n",
            "+4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cell = pd.DataFrame()\n",
        "cell1 = pd.DataFrame()\n",
        "\n",
        "cell['text'] =df1[0]\n",
        "cell['retweet_count'] =df1[2]\n",
        "cell['favorite_count'] =df1[3]\n",
        "\n",
        "cell1['text'] =df[0]\n",
        "cell1['retweet_count'] =df[2]\n",
        "cell1['favorite_count'] =df[3]\n",
        "\n",
        "\n",
        "cell_nugs= pd.DataFrame()\n",
        "cell_nugs['text'] = df_nugs[0]\n",
        "cell_nugs['retweet_count'] =df_nugs[2]\n",
        "cell_nugs['favorite_count'] =df_nugs[3]\n",
        "\n",
        "\n",
        "cell_wars = pd.DataFrame()\n",
        "cell_wars['text'] = df_wars[0]\n",
        "cell_wars['retweet_count'] =df_wars[2]\n",
        "cell_wars['favorite_count'] =df_wars[3]\n",
        "\n",
        "cell_bulls= pd.DataFrame()\n",
        "cell_bulls['text'] = df_bulls[0]\n",
        "cell_bulls['retweet_count'] =df_bulls[2]\n",
        "cell_bulls['favorite_count'] =df_bulls[3]\n",
        "\n",
        "cell_bucks = pd.DataFrame()\n",
        "cell_bucks['text'] = df_bucks[0]\n",
        "cell_bucks['retweet_count'] =df_bucks[2]\n",
        "cell_bucks['favorite_count'] =df_bucks[3]"
      ],
      "metadata": {
        "id": "VcK7sEcVhxSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = cell1.text.values.tolist()\n",
        "data_words = list(sent_to_words(data))\n",
        "data_wordss = remove_stopwords(data_words)\n",
        "\n",
        "\n",
        "bigram = gensim.models.Phrases(data_wordss, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_wordss], threshold=100)  \n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "data_ready = process_words(data_words)  \n",
        "\n",
        "celll =[]\n",
        "import re\n",
        "\n",
        "for sfw in range(len(cell['text'])):\n",
        "  tr = re.sub(\"[^0-9]\", \",\", cell['text'][sfw]).split(',')\n",
        "  gg = []\n",
        "  for xc in range(len(tr)):\n",
        "    if len(tr[xc])==0:\n",
        "      faf = 0\n",
        "    else:\n",
        "      gg.append(tr[xc])\n",
        "  celll.append(gg)\n",
        "\n",
        "\n",
        "celtics = pd.DataFrame()\n",
        "celtics['text'] = cell['text']\n",
        "celtics['retweet_count'] = cell1['retweet_count']\n",
        "celtics['favorite_count'] = cell1['favorite_count']\n",
        "\n",
        "celtics = pd.merge(celtics.reset_index(), pd.DataFrame(data_words).reset_index(), on = 'index').drop(columns = ['index'])\n",
        "celtics = pd.merge(celtics.reset_index(), pd.DataFrame(celll).reset_index(), on = 'index').drop(columns = 'index')\n",
        "print('input search term')\n",
        "search = input().lower()\n",
        "print('input the opposing team')\n",
        "other = input().lower()\n",
        "print('enter the nickname of the search term')\n",
        "nickname = input().lower()\n",
        "print('enter the nickname of the opp term')\n",
        "nickname1 = input().lower()\n",
        "print('input the search teams line')\n",
        "line_search = float(input())\n",
        "print('input the opps team line')\n",
        "line_op = float(input())\n",
        "\n",
        "cc = []\n",
        "for x in range(len(celtics['text'])):\n",
        "  cc.append(nickname)\n",
        "celtics['nickname_search'] = cc\n",
        "\n",
        "cc = []\n",
        "for x in range(len(celtics['text'])):\n",
        "  cc.append(search)\n",
        "celtics['team'] = cc\n",
        "\n",
        "cc = []\n",
        "for x in range(len(celtics['text'])):\n",
        "  cc.append(other)\n",
        "celtics['op_team'] = cc\n",
        "\n",
        "cc = []\n",
        "for x in range(len(celtics['text'])):\n",
        "  cc.append(nickname1)\n",
        "celtics['nickname_op'] = cc\n",
        "cc = []\n",
        "for x in range(len(celtics['text'])):\n",
        "  cc.append(line_search)\n",
        "celtics['search_line'] = cc\n",
        "cc = []\n",
        "for x in range(len(celtics['text'])):\n",
        "  cc.append(line_op)\n",
        "celtics['op_line'] = cc\n",
        "\n",
        "df111 = celtics\n",
        "\n",
        "print('search again? (yes/no)')\n",
        "sss = input().lower()\n",
        "if sss =='no':\n",
        "  print('enter yes!')\n",
        "else:\n",
        "\n",
        "  data = cell.text.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  data_wordss = remove_stopwords(data_words)\n",
        "\n",
        "\n",
        "  bigram = gensim.models.Phrases(data_wordss, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_wordss], threshold=100)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "  data_ready = process_words(data_words)  \n",
        "\n",
        "  celll =[]\n",
        "  import re\n",
        "\n",
        "  for sfw in range(len(cell['text'])):\n",
        "    tr = re.sub(\"[^0-9]\", \",\", cell['text'][sfw]).split(',')\n",
        "    gg = []\n",
        "    for xc in range(len(tr)):\n",
        "      if len(tr[xc])==0:\n",
        "        faf = 0\n",
        "      else:\n",
        "        gg.append(tr[xc])\n",
        "    celll.append(gg)\n",
        "\n",
        "\n",
        "  celtics = pd.DataFrame()\n",
        "  celtics['text'] = cell['text']\n",
        "  celtics['retweet_count'] = cell['retweet_count']\n",
        "  celtics['favorite_count'] = cell['favorite_count']\n",
        "\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(data_words).reset_index(), on = 'index').drop(columns = ['index'])\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(celll).reset_index(), on = 'index').drop(columns = 'index')\n",
        "  print('input search term')\n",
        "  search = input().lower()\n",
        "  print('input the opposing team')\n",
        "  other = input().lower()\n",
        "  print('enter the nickname of the search term')\n",
        "  nickname = input().lower()\n",
        "  print('enter the nickname of the opp term')\n",
        "  nickname1 = input().lower()\n",
        "  print('input the search teams line')\n",
        "  line_search = float(input())\n",
        "  print('input the opps team line')\n",
        "  line_op = float(input())\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(nickname)\n",
        "  celtics['nickname_search'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(search)\n",
        "  celtics['team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(other)\n",
        "  celtics['op_team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(nickname1)\n",
        "  celtics['nickname_op'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(line_search)\n",
        "  celtics['search_line'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(line_op)\n",
        "  celtics['op_line'] = cc\n",
        "\n",
        "  df112 = df111.append(celtics)\n",
        "\n",
        "if sss =='no':\n",
        "  print('enter yes!')\n",
        "else:\n",
        "\n",
        "  data = cell_bucks.text.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  data_wordss = remove_stopwords(data_words)\n",
        "\n",
        "\n",
        "  bigram = gensim.models.Phrases(data_wordss, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_wordss], threshold=100)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "  data_ready = process_words(data_words)  \n",
        "\n",
        "  celll =[]\n",
        "  import re\n",
        "\n",
        "  for sfw in range(len(cell['text'])):\n",
        "    tr = re.sub(\"[^0-9]\", \",\", cell['text'][sfw]).split(',')\n",
        "    gg = []\n",
        "    for xc in range(len(tr)):\n",
        "      if len(tr[xc])==0:\n",
        "        faf = 0\n",
        "      else:\n",
        "        gg.append(tr[xc])\n",
        "    celll.append(gg)\n",
        "\n",
        "\n",
        "  celtics = pd.DataFrame()\n",
        "  celtics['text'] = cell['text']\n",
        "  celtics['retweet_count'] = cell_bucks['retweet_count']\n",
        "  celtics['favorite_count'] = cell_bucks['favorite_count']\n",
        "\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(data_words).reset_index(), on = 'index').drop(columns = ['index'])\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(celll).reset_index(), on = 'index').drop(columns = 'index')\n",
        "  print('input search term')\n",
        "  search = input().lower()\n",
        "  print('input the opposing team')\n",
        "  other = input().lower()\n",
        "  print('enter the nickname of the search term')\n",
        "  nickname = input().lower()\n",
        "  print('enter the nickname of the opp term')\n",
        "  nickname1 = input().lower()\n",
        "  print('input the search teams line')\n",
        "  line_search = float(input())\n",
        "  print('input the opps team line')\n",
        "  line_op = float(input())\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(nickname)\n",
        "  celtics['nickname_search'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(search)\n",
        "  celtics['team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(other)\n",
        "  celtics['op_team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(nickname1)\n",
        "  celtics['nickname_op'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(line_search)\n",
        "  celtics['search_line'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(line_op)\n",
        "  celtics['op_line'] = cc\n",
        "\n",
        "  df112 = df111.append(celtics)\n",
        "\n",
        "if sss =='no':\n",
        "  print('enter yes!')\n",
        "else:\n",
        "\n",
        "  data = cell_bulls.text.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  data_wordss = remove_stopwords(data_words)\n",
        "\n",
        "\n",
        "  bigram = gensim.models.Phrases(data_wordss, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_wordss], threshold=100)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "  data_ready = process_words(data_words)  \n",
        "\n",
        "  celll =[]\n",
        "  import re\n",
        "\n",
        "  for sfw in range(len(cell['text'])):\n",
        "    tr = re.sub(\"[^0-9]\", \",\", cell['text'][sfw]).split(',')\n",
        "    gg = []\n",
        "    for xc in range(len(tr)):\n",
        "      if len(tr[xc])==0:\n",
        "        faf = 0\n",
        "      else:\n",
        "        gg.append(tr[xc])\n",
        "    celll.append(gg)\n",
        "\n",
        "\n",
        "  celtics = pd.DataFrame()\n",
        "  celtics['text'] = cell['text']\n",
        "  celtics['retweet_count'] = cell_bulls['retweet_count']\n",
        "  celtics['favorite_count'] = cell_bulls['favorite_count']\n",
        "\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(data_words).reset_index(), on = 'index').drop(columns = ['index'])\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(celll).reset_index(), on = 'index').drop(columns = 'index')\n",
        "  print('input search term')\n",
        "  search = input().lower()\n",
        "  print('input the opposing team')\n",
        "  other = input().lower()\n",
        "  print('enter the nickname of the search term')\n",
        "  nickname = input().lower()\n",
        "  print('enter the nickname of the opp term')\n",
        "  nickname1 = input().lower()\n",
        "  print('input the search teams line')\n",
        "  line_search = float(input())\n",
        "  print('input the opps team line')\n",
        "  line_op = float(input())\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(nickname)\n",
        "  celtics['nickname_search'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(search)\n",
        "  celtics['team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(other)\n",
        "  celtics['op_team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(nickname1)\n",
        "  celtics['nickname_op'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(line_search)\n",
        "  celtics['search_line'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(line_op)\n",
        "  celtics['op_line'] = cc\n",
        "\n",
        "  df112 = df111.append(celtics)\n",
        "\n",
        "\n",
        "if sss =='no':\n",
        "  print('enter yes!')\n",
        "else:\n",
        "\n",
        "  data = cell_wars.text.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  data_wordss = remove_stopwords(data_words)\n",
        "\n",
        "\n",
        "  bigram = gensim.models.Phrases(data_wordss, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_wordss], threshold=100)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "  data_ready = process_words(data_words)  \n",
        "\n",
        "  celll =[]\n",
        "  import re\n",
        "\n",
        "  for sfw in range(len(cell['text'])):\n",
        "    tr = re.sub(\"[^0-9]\", \",\", cell['text'][sfw]).split(',')\n",
        "    gg = []\n",
        "    for xc in range(len(tr)):\n",
        "      if len(tr[xc])==0:\n",
        "        faf = 0\n",
        "      else:\n",
        "        gg.append(tr[xc])\n",
        "    celll.append(gg)\n",
        "\n",
        "\n",
        "  celtics = pd.DataFrame()\n",
        "  celtics['text'] = cell['text']\n",
        "  celtics['retweet_count'] = cell_wars['retweet_count']\n",
        "  celtics['favorite_count'] = cell_wars['favorite_count']\n",
        "\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(data_words).reset_index(), on = 'index').drop(columns = ['index'])\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(celll).reset_index(), on = 'index').drop(columns = 'index')\n",
        "  print('input search term')\n",
        "  search = input().lower()\n",
        "  print('input the opposing team')\n",
        "  other = input().lower()\n",
        "  print('enter the nickname of the search term')\n",
        "  nickname = input().lower()\n",
        "  print('enter the nickname of the opp term')\n",
        "  nickname1 = input().lower()\n",
        "  print('input the search teams line')\n",
        "  line_search = float(input())\n",
        "  print('input the opps team line')\n",
        "  line_op = float(input())\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(nickname)\n",
        "  celtics['nickname_search'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(search)\n",
        "  celtics['team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(other)\n",
        "  celtics['op_team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(nickname1)\n",
        "  celtics['nickname_op'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(line_search)\n",
        "  celtics['search_line'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(line_op)\n",
        "  celtics['op_line'] = cc\n",
        "\n",
        "  df112 = df111.append(celtics)\n",
        "\n",
        "\n",
        "if sss =='no':\n",
        "  print('enter yes!')\n",
        "else:\n",
        "\n",
        "  data = cell_nugs.text.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  data_wordss = remove_stopwords(data_words)\n",
        "\n",
        "\n",
        "  bigram = gensim.models.Phrases(data_wordss, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_wordss], threshold=100)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "  data_ready = process_words(data_words)  \n",
        "\n",
        "  celll =[]\n",
        "  import re\n",
        "\n",
        "  for sfw in range(len(cell['text'])):\n",
        "    tr = re.sub(\"[^0-9]\", \",\", cell['text'][sfw]).split(',')\n",
        "    gg = []\n",
        "    for xc in range(len(tr)):\n",
        "      if len(tr[xc])==0:\n",
        "        faf = 0\n",
        "      else:\n",
        "        gg.append(tr[xc])\n",
        "    celll.append(gg)\n",
        "\n",
        "\n",
        "  celtics = pd.DataFrame()\n",
        "  celtics['text'] = cell['text']\n",
        "  celtics['retweet_count'] = cell_nugs['retweet_count']\n",
        "  celtics['favorite_count'] = cell_nugs['favorite_count']\n",
        "\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(data_words).reset_index(), on = 'index').drop(columns = ['index'])\n",
        "  celtics = pd.merge(celtics.reset_index(), pd.DataFrame(celll).reset_index(), on = 'index').drop(columns = 'index')\n",
        "  print('input search term')\n",
        "  search = input().lower()\n",
        "  print('input the opposing team')\n",
        "  other = input().lower()\n",
        "  print('enter the nickname of the search term')\n",
        "  nickname = input().lower()\n",
        "  print('enter the nickname of the opp term')\n",
        "  nickname1 = input().lower()\n",
        "  print('input the search teams line')\n",
        "  line_search = float(input())\n",
        "  print('input the opps team line')\n",
        "  line_op = float(input())\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(nickname)\n",
        "  celtics['nickname_search'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(search)\n",
        "  celtics['team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(other)\n",
        "  celtics['op_team'] = cc\n",
        "\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(nickname1)\n",
        "  celtics['nickname_op'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(line_search)\n",
        "  celtics['search_line'] = cc\n",
        "  cc = []\n",
        "  for x in range(len(celtics['text'])):\n",
        "    cc.append(line_op)\n",
        "  celtics['op_line'] = cc\n",
        "\n",
        "  df112 = df111.append(celtics)\n",
        "\n",
        "\n",
        "\n",
        "df112"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HGqQlp2CHkrJ",
        "outputId": "cb560744-5059-4a8c-85fe-77d796cd85f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input search term\n",
            "celtics\n",
            "input the opposing team\n",
            "nets\n",
            "enter the nickname of the search term\n",
            "boston\n",
            "enter the nickname of the opp term\n",
            "brooklyn\n",
            "input the search teams line\n",
            "+1.5\n",
            "input the opps team line\n",
            "-1.5\n",
            "search again? (yes/no)\n",
            "yes\n",
            "input search term\n",
            "nets\n",
            "input the opposing team\n",
            "celtics\n",
            "enter the nickname of the search term\n",
            "brooklyn\n",
            "enter the nickname of the opp term\n",
            "boston\n",
            "input the search teams line\n",
            "-1.5\n",
            "input the opps team line\n",
            "+1.5\n",
            "input search term\n",
            "bucks\n",
            "input the opposing team\n",
            "bulls\n",
            "enter the nickname of the search term\n",
            "mlk\n",
            "enter the nickname of the opp term\n",
            "chicago\n",
            "input the search teams line\n",
            "-4.5\n",
            "input the opps team line\n",
            "+4.5\n",
            "input search term\n",
            "bulls\n",
            "input the opposing team\n",
            "bucks\n",
            "enter the nickname of the search term\n",
            "chicago\n",
            "enter the nickname of the opp term\n",
            "mlk\n",
            "input the search teams line\n",
            "+4.5\n",
            "input the opps team line\n",
            "-4.5\n",
            "input search term\n",
            "warriors\n",
            "input the opposing team\n",
            "nuggets\n",
            "enter the nickname of the search term\n",
            "golden\n",
            "enter the nickname of the opp term\n",
            "denver\n",
            "input the search teams line\n",
            "-4.5\n",
            "input the opps team line\n",
            "+4.5\n",
            "input search term\n",
            "nuggets\n",
            "input the opposing team\n",
            "warriors\n",
            "enter the nickname of the search term\n",
            "denver\n",
            "enter the nickname of the opp term\n",
            "golden\n",
            "input the search teams line\n",
            "+4.5\n",
            "input the opps team line\n",
            "-4.5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  retweet_count  \\\n",
              "0    Reseeding NBA teams based on what i've seen ov...         0.0000   \n",
              "1    Seeing Nets still at 1.5%-2% to win the whole ...         0.0000   \n",
              "2    @MattArchambeau1 @BGN_5 Houston was on a rebui...         4.0000   \n",
              "3    Ben on the sideline pretending he is disappoin...         0.0000   \n",
              "4    NBAs Top 10 Selling Jerseys:\\n#1 Lakers LeBr...         2.0000   \n",
              "..                                                 ...            ...   \n",
              "229  Cs.\\n1. Better Team\\n2. Deeper Team \\n3. Def...         0.0000   \n",
              "230  @EvanRobertsWFAN For you Nets sk for Carton b...         0.0000   \n",
              "231  Q4 5:21 BOS 96  BKN 86\\nKyrie Irving has tied...         0.0000   \n",
              "232  Q4 5:21 BOS 96  BKN 86\\nKyrie Irving has tied...         0.0000   \n",
              "233  Past 24 hours we got Cuse women's lax losing t...         0.0000   \n",
              "\n",
              "     favorite_count            0_x      1_x      2_x       3_x          4_x  \\\n",
              "0            0.0000      reseeding      nba    teams     based           on   \n",
              "1            0.0000         marcus    smart   panini    rookie  sportscards   \n",
              "2            9.0000          takin       it     easy      this       sunday   \n",
              "3           20.0000            nba      top  selling   jerseys       lakers   \n",
              "4            0.0000    sayittwice_       if  giannis     beats          the   \n",
              "..              ...            ...      ...      ...       ...          ...   \n",
              "229          1.0000  getnickwright    kevin   durant        is          one   \n",
              "230         12.0000           bgn_  shannon  sharpes  greatest          nba   \n",
              "231          0.0000         jordan    poole   points      prop          has   \n",
              "232          0.0000         update   golden    state  warriors           at   \n",
              "233          5.0000           here       we     grow    sports          and   \n",
              "\n",
              "           5_x           6_x  ...  16_y  17_y  18_y  19_y nickname_search  \\\n",
              "0         what            ve  ...  None  None  None  None          boston   \n",
              "1        https            co  ...  None  None  None  None          boston   \n",
              "2          one           mlb  ...  None  None  None  None          boston   \n",
              "3       lebron         james  ...  None  None  None  None          boston   \n",
              "4      celtics       without  ...  None  None  None  None          boston   \n",
              "..         ...           ...  ...   ...   ...   ...   ...             ...   \n",
              "229       loss          away  ...  None  None  None  None          denver   \n",
              "230    playoff  performances  ...  None  None  None  None          denver   \n",
              "231       been           set  ...  None  None  None  None          denver   \n",
              "232     denver       nuggets  ...  None  None  None  None          denver   \n",
              "233  breakfast            on  ...  None  None  None  None          denver   \n",
              "\n",
              "        team   op_team nickname_op search_line op_line  \n",
              "0    celtics      nets    brooklyn      1.5000 -1.5000  \n",
              "1    celtics      nets    brooklyn      1.5000 -1.5000  \n",
              "2    celtics      nets    brooklyn      1.5000 -1.5000  \n",
              "3    celtics      nets    brooklyn      1.5000 -1.5000  \n",
              "4    celtics      nets    brooklyn      1.5000 -1.5000  \n",
              "..       ...       ...         ...         ...     ...  \n",
              "229  nuggets  warriors      golden      4.5000 -4.5000  \n",
              "230  nuggets  warriors      golden      4.5000 -4.5000  \n",
              "231  nuggets  warriors      golden      4.5000 -4.5000  \n",
              "232  nuggets  warriors      golden      4.5000 -4.5000  \n",
              "233  nuggets  warriors      golden      4.5000 -4.5000  \n",
              "\n",
              "[514 rows x 57 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a09a5c4-1667-4e98-8a5c-078fb42551b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>0_x</th>\n",
              "      <th>1_x</th>\n",
              "      <th>2_x</th>\n",
              "      <th>3_x</th>\n",
              "      <th>4_x</th>\n",
              "      <th>5_x</th>\n",
              "      <th>6_x</th>\n",
              "      <th>...</th>\n",
              "      <th>16_y</th>\n",
              "      <th>17_y</th>\n",
              "      <th>18_y</th>\n",
              "      <th>19_y</th>\n",
              "      <th>nickname_search</th>\n",
              "      <th>team</th>\n",
              "      <th>op_team</th>\n",
              "      <th>nickname_op</th>\n",
              "      <th>search_line</th>\n",
              "      <th>op_line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Reseeding NBA teams based on what i've seen ov...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>reseeding</td>\n",
              "      <td>nba</td>\n",
              "      <td>teams</td>\n",
              "      <td>based</td>\n",
              "      <td>on</td>\n",
              "      <td>what</td>\n",
              "      <td>ve</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>boston</td>\n",
              "      <td>celtics</td>\n",
              "      <td>nets</td>\n",
              "      <td>brooklyn</td>\n",
              "      <td>1.5000</td>\n",
              "      <td>-1.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Seeing Nets still at 1.5%-2% to win the whole ...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>marcus</td>\n",
              "      <td>smart</td>\n",
              "      <td>panini</td>\n",
              "      <td>rookie</td>\n",
              "      <td>sportscards</td>\n",
              "      <td>https</td>\n",
              "      <td>co</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>boston</td>\n",
              "      <td>celtics</td>\n",
              "      <td>nets</td>\n",
              "      <td>brooklyn</td>\n",
              "      <td>1.5000</td>\n",
              "      <td>-1.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@MattArchambeau1 @BGN_5 Houston was on a rebui...</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>9.0000</td>\n",
              "      <td>takin</td>\n",
              "      <td>it</td>\n",
              "      <td>easy</td>\n",
              "      <td>this</td>\n",
              "      <td>sunday</td>\n",
              "      <td>one</td>\n",
              "      <td>mlb</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>boston</td>\n",
              "      <td>celtics</td>\n",
              "      <td>nets</td>\n",
              "      <td>brooklyn</td>\n",
              "      <td>1.5000</td>\n",
              "      <td>-1.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ben on the sideline pretending he is disappoin...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>20.0000</td>\n",
              "      <td>nba</td>\n",
              "      <td>top</td>\n",
              "      <td>selling</td>\n",
              "      <td>jerseys</td>\n",
              "      <td>lakers</td>\n",
              "      <td>lebron</td>\n",
              "      <td>james</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>boston</td>\n",
              "      <td>celtics</td>\n",
              "      <td>nets</td>\n",
              "      <td>brooklyn</td>\n",
              "      <td>1.5000</td>\n",
              "      <td>-1.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NBAs Top 10 Selling Jerseys:\\n#1 Lakers LeBr...</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>sayittwice_</td>\n",
              "      <td>if</td>\n",
              "      <td>giannis</td>\n",
              "      <td>beats</td>\n",
              "      <td>the</td>\n",
              "      <td>celtics</td>\n",
              "      <td>without</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>boston</td>\n",
              "      <td>celtics</td>\n",
              "      <td>nets</td>\n",
              "      <td>brooklyn</td>\n",
              "      <td>1.5000</td>\n",
              "      <td>-1.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>Cs.\\n1. Better Team\\n2. Deeper Team \\n3. Def...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>getnickwright</td>\n",
              "      <td>kevin</td>\n",
              "      <td>durant</td>\n",
              "      <td>is</td>\n",
              "      <td>one</td>\n",
              "      <td>loss</td>\n",
              "      <td>away</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>denver</td>\n",
              "      <td>nuggets</td>\n",
              "      <td>warriors</td>\n",
              "      <td>golden</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>-4.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>@EvanRobertsWFAN For you Nets sk for Carton b...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>12.0000</td>\n",
              "      <td>bgn_</td>\n",
              "      <td>shannon</td>\n",
              "      <td>sharpes</td>\n",
              "      <td>greatest</td>\n",
              "      <td>nba</td>\n",
              "      <td>playoff</td>\n",
              "      <td>performances</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>denver</td>\n",
              "      <td>nuggets</td>\n",
              "      <td>warriors</td>\n",
              "      <td>golden</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>-4.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>Q4 5:21 BOS 96  BKN 86\\nKyrie Irving has tied...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>jordan</td>\n",
              "      <td>poole</td>\n",
              "      <td>points</td>\n",
              "      <td>prop</td>\n",
              "      <td>has</td>\n",
              "      <td>been</td>\n",
              "      <td>set</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>denver</td>\n",
              "      <td>nuggets</td>\n",
              "      <td>warriors</td>\n",
              "      <td>golden</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>-4.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>Q4 5:21 BOS 96  BKN 86\\nKyrie Irving has tied...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>update</td>\n",
              "      <td>golden</td>\n",
              "      <td>state</td>\n",
              "      <td>warriors</td>\n",
              "      <td>at</td>\n",
              "      <td>denver</td>\n",
              "      <td>nuggets</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>denver</td>\n",
              "      <td>nuggets</td>\n",
              "      <td>warriors</td>\n",
              "      <td>golden</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>-4.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>Past 24 hours we got Cuse women's lax losing t...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>here</td>\n",
              "      <td>we</td>\n",
              "      <td>grow</td>\n",
              "      <td>sports</td>\n",
              "      <td>and</td>\n",
              "      <td>breakfast</td>\n",
              "      <td>on</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>denver</td>\n",
              "      <td>nuggets</td>\n",
              "      <td>warriors</td>\n",
              "      <td>golden</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>-4.5000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>514 rows  57 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a09a5c4-1667-4e98-8a5c-078fb42551b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a09a5c4-1667-4e98-8a5c-078fb42551b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a09a5c4-1667-4e98-8a5c-078fb42551b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fff = df112.sample(n = 500)\n",
        "\n",
        "fff['ttt'] = fff['0_x'].astype(str)+' '+fff['2_x'].astype(str)+' '+fff['3_x'].astype(str)+' '+fff['4_x'].astype(str)+' '+fff['5_x'].astype(str)+' '+fff['6_x'].astype(str)+' '+fff['7_x'].astype(str)+' '+fff['8_x'].astype(str)+' '+fff['9_x'].astype(str)+' '+fff['10_x'].astype(str)+' '+fff['11_x'].astype(str)+' '+fff['12_x'].astype(str)+' '+fff['13_x'].astype(str)+' '+fff['14_x'].astype(str)+' '+fff['15_x'].astype(str)+' '+fff['16_x'].astype(str)+' '+fff['17_x'].astype(str)+' '+fff['18_x'].astype(str)+' '+fff['19_x'].astype(str)+fff['19_x'].astype(str)\n",
        "\n",
        "fff['ttt'] = fff['ttt'].reset_index().drop(columns = 'index')\n",
        "fff = fff.reset_index().drop(columns = 'index')\n",
        "\n",
        "import texthero as hero\n",
        "from texthero import preprocessing\n",
        "custom_pipeline = [preprocessing.fillna,\n",
        "                   preprocessing.lowercase,\n",
        "                   preprocessing.remove_whitespace,\n",
        "                   preprocessing.remove_diacritics,\n",
        "                   preprocessing.remove_brackets\n",
        "                  ]\n",
        "df = pd.DataFrame()\n",
        "df['clean_text'] = hero.clean(fff['ttt'] , custom_pipeline)\n",
        "df['clean_text'] = [n.replace('{','') for n in df['clean_text']]\n",
        "df['clean_text'] = [n.replace('}','') for n in df['clean_text']]\n",
        "df['clean_text'] = [n.replace('(','') for n in df['clean_text']]\n",
        "df['clean_text'] = [n.replace(')','') for n in df['clean_text']]\n",
        "\n",
        "\n",
        "df['tfidf'] = (hero.tfidf(df['clean_text'], max_features=30000))\n",
        "card_docs = [TaggedDocument(doc.split(' '), [i]) \n",
        "             for i, doc in enumerate(df.clean_text)]\n",
        "model = Doc2Vec(vector_size=64, min_count=1, epochs = 20)\n",
        "model = Doc2Vec(vector_size=64, window=2, min_count=1, workers=8, epochs = 40)\n",
        "model.build_vocab(card_docs)\n",
        "model.train(card_docs, total_examples=model.corpus_count\n",
        "            , epochs=model.epochs)\n",
        "card2vec = [model.infer_vector((df['clean_text'][i].split(' '))) \n",
        "            for i in range(0,len(df['clean_text']))]\n",
        "dtv= np.array(card2vec).tolist()\n",
        "df['card2vec'] = dtv\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
        "embeddings = embed(df['clean_text'])\n",
        "use= np.array(embeddings).tolist()\n",
        "df['use'] = [v for v in use]\n",
        "df['tsnetfidf'] = hero.tsne(df['tfidf'])\n",
        "df['tsnec2v'] = hero.tsne(df['card2vec'])\n",
        "df['tsneuse'] = hero.tsne(df['use'])\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "from collections import Counter\n",
        "\n",
        "df['line'] = df['clean_text'].str.replace(',', '')\n",
        "df['line'] = df['clean_text'].str.replace('.', '')\n",
        "\n",
        "df['celtics'] = df['clean_text'].map(lambda x: x.count(\"celtics\"))\n",
        "df['nets'] = df['clean_text'].map(lambda x: x.count(\"nets\"))\n",
        "\n",
        "df['bucks'] = df['clean_text'].map(lambda x: x.count(\"bucks\"))\n",
        "df['bulls'] = df['clean_text'].map(lambda x: x.count(\"bulls\"))\n",
        "\n",
        "df['warriors'] = df['clean_text'].map(lambda x: x.count(\"warriors\"))\n",
        "df['nuggets'] = df['clean_text'].map(lambda x: x.count(\"nuggets\"))\n",
        "\n",
        "df['boston'] = df['clean_text'].map(lambda x: x.count(\"boston\"))\n",
        "df['brooklyn'] = df['clean_text'].map(lambda x: x.count(\"brooklyn\"))\n",
        "\n",
        "df['milwaukee'] = df['clean_text'].map(lambda x: x.count(\"milwaukee\"))\n",
        "df['chicago'] = df['clean_text'].map(lambda x: x.count(\"chicago\"))\n",
        "\n",
        "df['golden'] = df['clean_text'].map(lambda x: x.count(\"golden\"))\n",
        "df['denver'] = df['clean_text'].map(lambda x: x.count(\"denver\"))\n",
        "\n",
        "df['ml'] = df['clean_text'].map(lambda x: x.count(\"ml\"))\n",
        "\n",
        "df['+'] = df['clean_text'].map(lambda x: x.count(\"+\"))\n",
        "df['-'] = df['clean_text'].map(lambda x: x.count(\"-\"))\n",
        "\n",
        "df['s_line'] = fff['search_line'].reset_index().drop_duplicates('index').drop(columns = 'index')\n",
        "df['op_line'] = fff['op_line'].reset_index().drop_duplicates('index').drop(columns = 'index')\n",
        "df['favorite_count'] = fff['op_line'].reset_index().drop_duplicates('index').drop(columns = 'index')\n",
        "df['retweet_count'] = fff['op_line'].reset_index().drop_duplicates('index').drop(columns = 'index')\n",
        "\n",
        "\n",
        "df['search_'] = fff['team'].map(lambda x: x.count(\"celtics\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "df['search1'] = fff['team'].map(lambda x: x.count(\"nets\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['search2'] = fff['team'].map(lambda x: x.count(\"nuggets\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['search3'] = fff['team'].map(lambda x: x.count(\"warriors\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['search4'] = fff['team'].map(lambda x: x.count(\"bulls\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['search5'] = fff['team'].map(lambda x: x.count(\"bucks\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "\n",
        "df['op_'] = fff['op_team'].map(lambda x: x.count(\"nets\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op1'] = fff['op_team'].map(lambda x: x.count(\"celtics\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op2'] = fff['op_team'].map(lambda x: x.count(\"warriors\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op3'] = fff['op_team'].map(lambda x: x.count(\"nuggets\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op4'] = fff['op_team'].map(lambda x: x.count(\"bulls\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op5'] = fff['op_team'].map(lambda x: x.count(\"bucks\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "\n",
        "\n",
        "df = df.drop(columns = ['line','tfidf','card2vec','tsnec2v'])\n",
        "\n",
        "\n",
        "holder = []\n",
        "holder1 = []\n",
        "for x in range(len(df['use'])):\n",
        "  holder.append(str(str(df['use'][1][0:30]).replace('[','').replace(']','')).split(','))\n",
        "for x in range(len(df['tsneuse'])):\n",
        "  holder1.append(str(str(df['use'][1][0:30]).replace('[','').replace(']','')).split(','))\n",
        "\n",
        "df = pd.merge(df.reset_index(),pd.DataFrame(holder).reset_index(),on = 'index').drop(columns = ['index','use'])\n",
        "df = pd.merge(df.reset_index(),pd.DataFrame(holder1).reset_index(),on = 'index').drop(columns = ['index'])\n",
        "df = pd.merge(df.reset_index(),pd.DataFrame(celll).reset_index().iloc[:,0:10],on = 'index').drop(columns = ['index']) \n",
        "df_textHold = df['clean_text']\n",
        "df = df.drop(columns = ['clean_text','tsnetfidf'])"
      ],
      "metadata": {
        "id": "7QWcWLdlHktV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24acb9d4-5976-48e6-ec73-122b1335ba85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns = 'tsneuse')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "EjKeK1IFnlev",
        "outputId": "24b3e203-b364-4af3-e8a8-dc4eccf7542d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     celtics  nets  bucks  bulls  warriors  nuggets  boston  brooklyn  \\\n",
              "0          0     0      0      0         0        0       0         0   \n",
              "1          2     1      0      0         0        0       0         0   \n",
              "2          0     0      0      0         0        0       0         0   \n",
              "3          1     1      0      0         0        0       0         0   \n",
              "4          0     0      1      0         0        0       0         0   \n",
              "..       ...   ...    ...    ...       ...      ...     ...       ...   \n",
              "275        0     0      0      0         0        0       0         0   \n",
              "276        0     0      0      0         0        0       0         0   \n",
              "277        0     0      0      0         1        1       0         0   \n",
              "278        0     0      0      0         0        1       0         0   \n",
              "279        0     0      0      0         0        2       0         0   \n",
              "\n",
              "     milwaukee  chicago  ...                  29_y   0   1     2     3     4  \\\n",
              "0            0        0  ...   0.03245069459080696   1   2     3     4     5   \n",
              "1            0        0  ...   0.03245069459080696   1   5     2  None  None   \n",
              "2            0        0  ...   0.03245069459080696   1   5    43  None  None   \n",
              "3            0        0  ...   0.03245069459080696   2   0  None  None  None   \n",
              "4            0        0  ...   0.03245069459080696  10   1     2    76     3   \n",
              "..         ...      ...  ...                   ...  ..  ..   ...   ...   ...   \n",
              "275          0        0  ...   0.03245069459080696  12   6     4     4    52   \n",
              "276          0        0  ...   0.03245069459080696   5  53  None  None  None   \n",
              "277          0        0  ...   0.03245069459080696   1   5    18    17    18   \n",
              "278          0        0  ...   0.03245069459080696   1   5    18    17    18   \n",
              "279          0        0  ...   0.03245069459080696   1   5    54    15    16   \n",
              "\n",
              "        5     6     7     8  \n",
              "0       3     3  None  None  \n",
              "1    None  None  None  None  \n",
              "2    None  None  None  None  \n",
              "3    None  None  None  None  \n",
              "4       4  None  None  None  \n",
              "..    ...   ...   ...   ...  \n",
              "275     4     4    12     5  \n",
              "276  None  None  None  None  \n",
              "277    21  None  None  None  \n",
              "278    21    79  None  None  \n",
              "279    18     8  None  None  \n",
              "\n",
              "[280 rows x 98 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8716d548-faf3-4a71-83bc-e9dc43e0354d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>celtics</th>\n",
              "      <th>nets</th>\n",
              "      <th>bucks</th>\n",
              "      <th>bulls</th>\n",
              "      <th>warriors</th>\n",
              "      <th>nuggets</th>\n",
              "      <th>boston</th>\n",
              "      <th>brooklyn</th>\n",
              "      <th>milwaukee</th>\n",
              "      <th>chicago</th>\n",
              "      <th>...</th>\n",
              "      <th>29_y</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03245069459080696</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03245069459080696</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03245069459080696</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>43</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03245069459080696</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03245069459080696</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>76</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03245069459080696</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>52</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03245069459080696</td>\n",
              "      <td>5</td>\n",
              "      <td>53</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03245069459080696</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>21</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03245069459080696</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>21</td>\n",
              "      <td>79</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03245069459080696</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>54</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>8</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>280 rows  98 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8716d548-faf3-4a71-83bc-e9dc43e0354d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8716d548-faf3-4a71-83bc-e9dc43e0354d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8716d548-faf3-4a71-83bc-e9dc43e0354d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.predict(df.fillna(0).astype(float))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ--QRj3nuKC",
        "outputId": "3008ef40-5dc8-4cd4-c7d9-ece060725020"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 1., 0., 2., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.predict(df.fillna(0).astype(float))\n",
        "resultz = pd.DataFrame()\n",
        "resultz = pd.DataFrame(clf.predict_proba(df.fillna(0).astype(float)))\n",
        "resultz['actual'] = y\n",
        "print(resultz.head(50))\n",
        "first = pd.DataFrame()\n",
        "second = pd.DataFrame()\n",
        "\n",
        "first = resultz[resultz[1]>=.33]\n",
        "second = resultz[resultz[2]>=.33]\n",
        "\n",
        "first"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7atzpo4jHkwF",
        "outputId": "8362b115-5fe0-4257-c8c5-134c6ae38ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0      1      2  actual\n",
            "0  0.4610 0.3520 0.1870  2.0000\n",
            "1  0.8281 0.0850 0.0869  0.0000\n",
            "2  0.3815 0.3402 0.2782  1.0000\n",
            "3  0.3343 0.4064 0.2593  1.0000\n",
            "4  0.4021 0.3280 0.2699  2.0000\n",
            "5  0.7411 0.1100 0.1489  0.0000\n",
            "6  0.3570 0.3530 0.2900  1.0000\n",
            "7  0.4891 0.2948 0.2162  0.0000\n",
            "8  0.8570 0.0010 0.1420  1.0000\n",
            "9  0.6498 0.0070 0.3432  0.0000\n",
            "10 0.4220 0.4027 0.1753  2.0000\n",
            "11 0.3580 0.3332 0.3089  0.0000\n",
            "12 0.8284 0.0840 0.0876  0.0000\n",
            "13 0.4448 0.3252 0.2299  1.0000\n",
            "14 0.7550 0.0500 0.1950  0.0000\n",
            "15 0.9035 0.0130 0.0835  1.0000\n",
            "16 0.4645 0.3050 0.2305  0.0000\n",
            "17 0.4060 0.3640 0.2300  1.0000\n",
            "18 0.4840 0.2580 0.2580  2.0000\n",
            "19 0.8382 0.0130 0.1488  1.0000\n",
            "20 0.3388 0.3187 0.3425  0.0000\n",
            "21 0.8609 0.0270 0.1121  2.0000\n",
            "22 0.7103 0.1100 0.1797  1.0000\n",
            "23 0.3710 0.3960 0.2330  2.0000\n",
            "24 0.4340 0.3140 0.2520  2.0000\n",
            "25 0.3658 0.3543 0.2798  1.0000\n",
            "26 0.8620 0.0240 0.1140  0.0000\n",
            "27 0.7710 0.0330 0.1960  2.0000\n",
            "28 0.4810 0.3110 0.2080  0.0000\n",
            "29 0.4537 0.3050 0.2413  0.0000\n",
            "30 0.3610 0.3383 0.3007  1.0000\n",
            "31 0.4093 0.3730 0.2177  2.0000\n",
            "32 0.8515 0.0310 0.1175  0.0000\n",
            "33 0.3690 0.3600 0.2710  1.0000\n",
            "34 0.7110 0.0890 0.2000  0.0000\n",
            "35 0.4597 0.3350 0.2053  2.0000\n",
            "36 0.7700 0.0330 0.1970  1.0000\n",
            "37 0.4700 0.2990 0.2310  0.0000\n",
            "38 0.8340 0.0840 0.0820  0.0000\n",
            "39 0.8992 0.0330 0.0678  2.0000\n",
            "40 0.3534 0.3455 0.3011  1.0000\n",
            "41 0.8995 0.0070 0.0935  0.0000\n",
            "42 0.4190 0.3440 0.2370  2.0000\n",
            "43 0.8350 0.0410 0.1240  2.0000\n",
            "44 0.3640 0.2990 0.3370  1.0000\n",
            "45 0.7588 0.0570 0.1842  1.0000\n",
            "46 0.7490 0.0220 0.2290  1.0000\n",
            "47 0.3792 0.3036 0.3172  0.0000\n",
            "48 0.4300 0.3600 0.2100  1.0000\n",
            "49 0.8882 0.0260 0.0858  2.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0      1      2  actual\n",
              "0   0.4610 0.3520 0.1870  2.0000\n",
              "2   0.3815 0.3402 0.2782  1.0000\n",
              "3   0.3343 0.4064 0.2593  1.0000\n",
              "6   0.3570 0.3530 0.2900  1.0000\n",
              "10  0.4220 0.4027 0.1753  2.0000\n",
              "..     ...    ...    ...     ...\n",
              "267 0.3039 0.3693 0.3268  2.0000\n",
              "268 0.4430 0.3520 0.2050  1.0000\n",
              "270 0.3939 0.3371 0.2690  1.0000\n",
              "273 0.3740 0.4753 0.1506  2.0000\n",
              "274 0.3582 0.4283 0.2135  1.0000\n",
              "\n",
              "[84 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-669f6870-2bf8-4cb8-a7c8-079274052493\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.4610</td>\n",
              "      <td>0.3520</td>\n",
              "      <td>0.1870</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.3815</td>\n",
              "      <td>0.3402</td>\n",
              "      <td>0.2782</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.3343</td>\n",
              "      <td>0.4064</td>\n",
              "      <td>0.2593</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.3570</td>\n",
              "      <td>0.3530</td>\n",
              "      <td>0.2900</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.4220</td>\n",
              "      <td>0.4027</td>\n",
              "      <td>0.1753</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>0.3039</td>\n",
              "      <td>0.3693</td>\n",
              "      <td>0.3268</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>0.4430</td>\n",
              "      <td>0.3520</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>0.3939</td>\n",
              "      <td>0.3371</td>\n",
              "      <td>0.2690</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>0.3740</td>\n",
              "      <td>0.4753</td>\n",
              "      <td>0.1506</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>0.3582</td>\n",
              "      <td>0.4283</td>\n",
              "      <td>0.2135</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84 rows  4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-669f6870-2bf8-4cb8-a7c8-079274052493')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-669f6870-2bf8-4cb8-a7c8-079274052493 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-669f6870-2bf8-4cb8-a7c8-079274052493');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AspPDgnwvfWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IcVIWv4yvfZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dB53BOOXvfeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "97szqBtXvfib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EzZjMEDBvfmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rDtImkzavfpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JqTXD8yHvfr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZWYPBDskvfuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scrapyard"
      ],
      "metadata": {
        "id": "9p2h2KKpHkye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "from collections import Counter\n",
        "\n",
        "df['line'] = df['clean_text'].str.replace(',', '')\n",
        "df['line'] = df['clean_text'].str.replace('.', '')\n",
        "\n",
        "df['celtics'] = df['clean_text'].map(lambda x: x.count(\"celtics\"))\n",
        "df['nets'] = df['clean_text'].map(lambda x: x.count(\"nets\"))\n",
        "\n",
        "df['bucks'] = df['clean_text'].map(lambda x: x.count(\"bucks\"))\n",
        "df['bulls'] = df['clean_text'].map(lambda x: x.count(\"bulls\"))\n",
        "\n",
        "df['warriors'] = df['clean_text'].map(lambda x: x.count(\"warriors\"))\n",
        "df['nuggets'] = df['clean_text'].map(lambda x: x.count(\"nuggets\"))\n",
        "\n",
        "df['boston'] = df['clean_text'].map(lambda x: x.count(\"boston\"))\n",
        "df['brooklyn'] = df['clean_text'].map(lambda x: x.count(\"brooklyn\"))\n",
        "\n",
        "df['milwaukee'] = df['clean_text'].map(lambda x: x.count(\"milwaukee\"))\n",
        "df['chicago'] = df['clean_text'].map(lambda x: x.count(\"chicago\"))\n",
        "\n",
        "df['golden'] = df['clean_text'].map(lambda x: x.count(\"golden\"))\n",
        "df['denver'] = df['clean_text'].map(lambda x: x.count(\"denver\"))\n",
        "\n",
        "df['ml'] = df['clean_text'].map(lambda x: x.count(\"ml\"))\n",
        "\n",
        "df['+'] = df['clean_text'].map(lambda x: x.count(\"+\"))\n",
        "df['-'] = df['clean_text'].map(lambda x: x.count(\"-\"))\n",
        "\n",
        "df['s_line'] = df_fin['search_line'].reset_index().drop_duplicates('index').drop(columns = 'index')\n",
        "df['op_line'] = df_fin['op_line'].reset_index().drop_duplicates('index').drop(columns = 'index')\n",
        "df['target'] = df_fin['target'].reset_index().drop_duplicates('index').reset_index().drop(columns = ['level_0','index'])\n",
        "\n",
        "df['search_'] = df_fin['team'].map(lambda x: x.count(\"celtics\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "df['search1'] = df_fin['team'].map(lambda x: x.count(\"nets\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['search2'] = df_fin['team'].map(lambda x: x.count(\"nuggets\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['search3'] = df_fin['team'].map(lambda x: x.count(\"warriors\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['search4'] = df_fin['team'].map(lambda x: x.count(\"bulls\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['search5'] = df_fin['team'].map(lambda x: x.count(\"bucks\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "\n",
        "df['op_'] = df_fin['op_team'].map(lambda x: x.count(\"nets\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op1'] = df_fin['op_team'].map(lambda x: x.count(\"celtics\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op2'] = df_fin['op_team'].map(lambda x: x.count(\"warriors\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op3'] = df_fin['op_team'].map(lambda x: x.count(\"nuggets\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op4'] = df_fin['op_team'].map(lambda x: x.count(\"bulls\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df['op5'] = df_fin['op_team'].map(lambda x: x.count(\"bucks\")).reset_index().drop_duplicates('index').reset_index().drop(columns = ['index','level_0'])\n",
        "\n",
        "df = df.drop(columns = ['line','clean_text','tfidf','card2vec','tsnetfidf','tsnec2v'])\n",
        "\n",
        "holder = []\n",
        "holder1 = []\n",
        "for x in range(len(df['use'])):\n",
        "  holder.append(str(str(df['use'][1][0:30]).replace('[','').replace(']','')).split(','))\n",
        "for x in range(len(df['tsneuse'])):\n",
        "  holder1.append(str(str(df['use'][1][0:30]).replace('[','').replace(']','')).split(','))\n",
        "\n",
        "df = pd.merge(df.reset_index(),pd.DataFrame(holder).reset_index(),on = 'index').drop(columns = ['index','use','tsneuse'])\n",
        "df = pd.merge(df.reset_index(),pd.DataFrame(holder1).reset_index(),on = 'index').drop(columns = ['index'])\n",
        "df = pd.merge(df.reset_index(),pd.DataFrame(celll).reset_index().iloc[:,0:10],on = 'index').drop(columns = ['index']) \n"
      ],
      "metadata": {
        "id": "TFF5dIkupS2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "holder = []\n",
        "holder1 = []\n",
        "for x in range(len(df['use'])):\n",
        "  holder.append(str(str(df['use'][1][0:30]).replace('[','').replace(']','')).split(','))\n",
        "for x in range(len(df['tsneuse'])):\n",
        "  holder1.append(str(str(df['use'][1][0:30]).replace('[','').replace(']','')).split(','))\n",
        "\n",
        "df = pd.merge(df.reset_index(),pd.DataFrame(holder).reset_index(),on = 'index').drop(columns = ['index','use','tsneuse'])\n",
        "df = pd.merge(df.reset_index(),pd.DataFrame(holder1).reset_index(),on = 'index').drop(columns = ['index'])\n",
        "df = pd.merge(df.reset_index(),pd.DataFrame(celll).reset_index().iloc[:,0:10],on = 'index').drop(columns = ['index']) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "PxLTXFYy_5lZ",
        "outputId": "ec3d9b40-0e5f-432c-cbe3-1b42a143b36f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     celtics  nets  bucks  bulls  warriors  nuggets  boston  brooklyn  \\\n",
              "0          0     0      0      0         0        1       0         0   \n",
              "1          0     0      0      0         1        0       0         0   \n",
              "2          0     0      0      0         0        1       0         0   \n",
              "3          0     0      0      0         1        0       0         0   \n",
              "4          0     0      0      0         0        0       0         0   \n",
              "..       ...   ...    ...    ...       ...      ...     ...       ...   \n",
              "995        0     0      0      0         1        0       0         0   \n",
              "996        0     0      0      0         1        0       0         0   \n",
              "997        0     0      0      0         0        0       0         0   \n",
              "998        0     0      0      0         1        0       0         0   \n",
              "999        0     0      0      0         0        0       0         0   \n",
              "\n",
              "     milwaukee  chicago  ...                   20_y                  21_y  \\\n",
              "0            0        0  ...   -0.08042887598276138   0.02054186910390854   \n",
              "1            0        0  ...   -0.08042887598276138   0.02054186910390854   \n",
              "2            0        0  ...   -0.08042887598276138   0.02054186910390854   \n",
              "3            0        0  ...   -0.08042887598276138   0.02054186910390854   \n",
              "4            0        0  ...   -0.08042887598276138   0.02054186910390854   \n",
              "..         ...      ...  ...                    ...                   ...   \n",
              "995          0        0  ...   -0.08042887598276138   0.02054186910390854   \n",
              "996          0        0  ...   -0.08042887598276138   0.02054186910390854   \n",
              "997          0        0  ...   -0.08042887598276138   0.02054186910390854   \n",
              "998          0        0  ...   -0.08042887598276138   0.02054186910390854   \n",
              "999          0        0  ...   -0.08042887598276138   0.02054186910390854   \n",
              "\n",
              "                       22_y                   23_y                  24_y  \\\n",
              "0     0.0038353761192411184   -0.02421613410115242   0.08084839582443237   \n",
              "1     0.0038353761192411184   -0.02421613410115242   0.08084839582443237   \n",
              "2     0.0038353761192411184   -0.02421613410115242   0.08084839582443237   \n",
              "3     0.0038353761192411184   -0.02421613410115242   0.08084839582443237   \n",
              "4     0.0038353761192411184   -0.02421613410115242   0.08084839582443237   \n",
              "..                      ...                    ...                   ...   \n",
              "995   0.0038353761192411184   -0.02421613410115242   0.08084839582443237   \n",
              "996   0.0038353761192411184   -0.02421613410115242   0.08084839582443237   \n",
              "997   0.0038353761192411184   -0.02421613410115242   0.08084839582443237   \n",
              "998   0.0038353761192411184   -0.02421613410115242   0.08084839582443237   \n",
              "999   0.0038353761192411184   -0.02421613410115242   0.08084839582443237   \n",
              "\n",
              "                     25_y                   26_y                    27_y  \\\n",
              "0     0.00596114806830883   0.048086345195770264   0.0011148544726893306   \n",
              "1     0.00596114806830883   0.048086345195770264   0.0011148544726893306   \n",
              "2     0.00596114806830883   0.048086345195770264   0.0011148544726893306   \n",
              "3     0.00596114806830883   0.048086345195770264   0.0011148544726893306   \n",
              "4     0.00596114806830883   0.048086345195770264   0.0011148544726893306   \n",
              "..                    ...                    ...                     ...   \n",
              "995   0.00596114806830883   0.048086345195770264   0.0011148544726893306   \n",
              "996   0.00596114806830883   0.048086345195770264   0.0011148544726893306   \n",
              "997   0.00596114806830883   0.048086345195770264   0.0011148544726893306   \n",
              "998   0.00596114806830883   0.048086345195770264   0.0011148544726893306   \n",
              "999   0.00596114806830883   0.048086345195770264   0.0011148544726893306   \n",
              "\n",
              "                      28_y                   29_y  \n",
              "0     -0.05205116793513298   0.002441949909552932  \n",
              "1     -0.05205116793513298   0.002441949909552932  \n",
              "2     -0.05205116793513298   0.002441949909552932  \n",
              "3     -0.05205116793513298   0.002441949909552932  \n",
              "4     -0.05205116793513298   0.002441949909552932  \n",
              "..                     ...                    ...  \n",
              "995   -0.05205116793513298   0.002441949909552932  \n",
              "996   -0.05205116793513298   0.002441949909552932  \n",
              "997   -0.05205116793513298   0.002441949909552932  \n",
              "998   -0.05205116793513298   0.002441949909552932  \n",
              "999   -0.05205116793513298   0.002441949909552932  \n",
              "\n",
              "[1000 rows x 90 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8340d08-94f5-431b-acea-af15efbaf9f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>celtics</th>\n",
              "      <th>nets</th>\n",
              "      <th>bucks</th>\n",
              "      <th>bulls</th>\n",
              "      <th>warriors</th>\n",
              "      <th>nuggets</th>\n",
              "      <th>boston</th>\n",
              "      <th>brooklyn</th>\n",
              "      <th>milwaukee</th>\n",
              "      <th>chicago</th>\n",
              "      <th>...</th>\n",
              "      <th>20_y</th>\n",
              "      <th>21_y</th>\n",
              "      <th>22_y</th>\n",
              "      <th>23_y</th>\n",
              "      <th>24_y</th>\n",
              "      <th>25_y</th>\n",
              "      <th>26_y</th>\n",
              "      <th>27_y</th>\n",
              "      <th>28_y</th>\n",
              "      <th>29_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.08042887598276138</td>\n",
              "      <td>0.02054186910390854</td>\n",
              "      <td>0.0038353761192411184</td>\n",
              "      <td>-0.02421613410115242</td>\n",
              "      <td>0.08084839582443237</td>\n",
              "      <td>0.00596114806830883</td>\n",
              "      <td>0.048086345195770264</td>\n",
              "      <td>0.0011148544726893306</td>\n",
              "      <td>-0.05205116793513298</td>\n",
              "      <td>0.002441949909552932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.08042887598276138</td>\n",
              "      <td>0.02054186910390854</td>\n",
              "      <td>0.0038353761192411184</td>\n",
              "      <td>-0.02421613410115242</td>\n",
              "      <td>0.08084839582443237</td>\n",
              "      <td>0.00596114806830883</td>\n",
              "      <td>0.048086345195770264</td>\n",
              "      <td>0.0011148544726893306</td>\n",
              "      <td>-0.05205116793513298</td>\n",
              "      <td>0.002441949909552932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.08042887598276138</td>\n",
              "      <td>0.02054186910390854</td>\n",
              "      <td>0.0038353761192411184</td>\n",
              "      <td>-0.02421613410115242</td>\n",
              "      <td>0.08084839582443237</td>\n",
              "      <td>0.00596114806830883</td>\n",
              "      <td>0.048086345195770264</td>\n",
              "      <td>0.0011148544726893306</td>\n",
              "      <td>-0.05205116793513298</td>\n",
              "      <td>0.002441949909552932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.08042887598276138</td>\n",
              "      <td>0.02054186910390854</td>\n",
              "      <td>0.0038353761192411184</td>\n",
              "      <td>-0.02421613410115242</td>\n",
              "      <td>0.08084839582443237</td>\n",
              "      <td>0.00596114806830883</td>\n",
              "      <td>0.048086345195770264</td>\n",
              "      <td>0.0011148544726893306</td>\n",
              "      <td>-0.05205116793513298</td>\n",
              "      <td>0.002441949909552932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.08042887598276138</td>\n",
              "      <td>0.02054186910390854</td>\n",
              "      <td>0.0038353761192411184</td>\n",
              "      <td>-0.02421613410115242</td>\n",
              "      <td>0.08084839582443237</td>\n",
              "      <td>0.00596114806830883</td>\n",
              "      <td>0.048086345195770264</td>\n",
              "      <td>0.0011148544726893306</td>\n",
              "      <td>-0.05205116793513298</td>\n",
              "      <td>0.002441949909552932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.08042887598276138</td>\n",
              "      <td>0.02054186910390854</td>\n",
              "      <td>0.0038353761192411184</td>\n",
              "      <td>-0.02421613410115242</td>\n",
              "      <td>0.08084839582443237</td>\n",
              "      <td>0.00596114806830883</td>\n",
              "      <td>0.048086345195770264</td>\n",
              "      <td>0.0011148544726893306</td>\n",
              "      <td>-0.05205116793513298</td>\n",
              "      <td>0.002441949909552932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.08042887598276138</td>\n",
              "      <td>0.02054186910390854</td>\n",
              "      <td>0.0038353761192411184</td>\n",
              "      <td>-0.02421613410115242</td>\n",
              "      <td>0.08084839582443237</td>\n",
              "      <td>0.00596114806830883</td>\n",
              "      <td>0.048086345195770264</td>\n",
              "      <td>0.0011148544726893306</td>\n",
              "      <td>-0.05205116793513298</td>\n",
              "      <td>0.002441949909552932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.08042887598276138</td>\n",
              "      <td>0.02054186910390854</td>\n",
              "      <td>0.0038353761192411184</td>\n",
              "      <td>-0.02421613410115242</td>\n",
              "      <td>0.08084839582443237</td>\n",
              "      <td>0.00596114806830883</td>\n",
              "      <td>0.048086345195770264</td>\n",
              "      <td>0.0011148544726893306</td>\n",
              "      <td>-0.05205116793513298</td>\n",
              "      <td>0.002441949909552932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.08042887598276138</td>\n",
              "      <td>0.02054186910390854</td>\n",
              "      <td>0.0038353761192411184</td>\n",
              "      <td>-0.02421613410115242</td>\n",
              "      <td>0.08084839582443237</td>\n",
              "      <td>0.00596114806830883</td>\n",
              "      <td>0.048086345195770264</td>\n",
              "      <td>0.0011148544726893306</td>\n",
              "      <td>-0.05205116793513298</td>\n",
              "      <td>0.002441949909552932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.08042887598276138</td>\n",
              "      <td>0.02054186910390854</td>\n",
              "      <td>0.0038353761192411184</td>\n",
              "      <td>-0.02421613410115242</td>\n",
              "      <td>0.08084839582443237</td>\n",
              "      <td>0.00596114806830883</td>\n",
              "      <td>0.048086345195770264</td>\n",
              "      <td>0.0011148544726893306</td>\n",
              "      <td>-0.05205116793513298</td>\n",
              "      <td>0.002441949909552932</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows  90 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8340d08-94f5-431b-acea-af15efbaf9f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8340d08-94f5-431b-acea-af15efbaf9f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8340d08-94f5-431b-acea-af15efbaf9f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    }
  ]
}