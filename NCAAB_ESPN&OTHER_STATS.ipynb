{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gg5riUOA8Bgl"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "CKa6nQKRcVcX",
    "outputId": "db673cb8-df0e-41ee-b950-02febfb95e39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_lines</th>\n",
       "      <th>team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Robert Morris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-4</td>\n",
       "      <td>Northern Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1</td>\n",
       "      <td>UConn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15</td>\n",
       "      <td>Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7</td>\n",
       "      <td>Detroit Mercy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    initial_lines               team\n",
       "6               7      Robert Morris\n",
       "8              -4  Northern Kentucky\n",
       "21             -1              UConn\n",
       "28             15           Maryland\n",
       "33              7      Detroit Mercy"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports\n",
    "#RUN ONLY 1 TIME: collects 'initial odds': therefore all differences will be 0 at time 0, as time goes on since running (and games start), the odds change\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from functools import reduce\n",
    "import time\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from datetime import datetime\n",
    "\n",
    "#function specific to json ex: https://sportsbook.fanduel.com/cache/psmg/US/53474.3.json\n",
    "def parse_data(jsooooon):\n",
    "    results = pd.DataFrame()\n",
    "    for ayo in jsooooon['events']:\n",
    "        money = json_normalize(ayo).drop('markets',axis=1)\n",
    "        for bandos in ayo['markets']:\n",
    "            gambling = json_normalize(bandos).drop('selections',axis=1)\n",
    "            gambling.columns = [str(col) + '.markets' for col in gambling.columns]\n",
    "            for theta in bandos['selections']:\n",
    "                yeye = json_normalize(theta)\n",
    "                yeye.columns = [str(col) + '.selections' for col in yeye.columns]\n",
    "                yoyo = reduce(lambda left,right: pd.merge(left,right, left_index=True, right_index=True), [money, gambling, yeye])\n",
    "                results = results.append(yoyo, sort=True).reset_index(drop=True)\n",
    "    return results\n",
    "\n",
    "#getting jsons, nfl doesnt work\n",
    "nfl = requests.get('https://sportsbook.fanduel.com/cache/psmg/UK/57494.3.json').json()\n",
    "nba = requests.get('https://sportsbook.fanduel.com/cache/psmg/UK/55978.3.json').json()\n",
    "bball = requests.get('https://sportsbook.fanduel.com/cache/psmg/US/53474.3.json').json()\n",
    "\n",
    "\n",
    "#setting up df\n",
    "cbb = parse_data(bball)\n",
    "cb = pd.DataFrame()\n",
    "cbb_ = cbb[cbb['name.markets']=='Spread Betting']\n",
    "cb[['lines','team','away_t','home_t','start_time']] = cbb_[['currenthandicap.selections','name.selections','participantname_away','participantname_home','tsstart']]\n",
    "\n",
    "away = cb[cb['team']==cb['away_t']]\n",
    "away['lines'] = away['lines'].astype(int)*-1\n",
    "home = cb[cb['team']==cb['home_t']]\n",
    "\n",
    "#RUN THIS CELL, THEN PREP WORK DONE (DONT RUN AGAIN!) --> ALL OF YOUR DIFFERENCES WILL BE 0 at first!!\n",
    "home_initial = pd.DataFrame()\n",
    "away_initial = pd.DataFrame()\n",
    "away_initial[['initial_lines','team']] = away[['lines','team']]\n",
    "home_initial[['initial_lines','team']] = home[['lines','team']]\n",
    "away_initial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "rCb3J_tIcVfE",
    "outputId": "6308e9b0-8eb8-42b5-fe2d-43893b8df109"
   },
   "outputs": [],
   "source": [
    "def game_lines(time_mins):\n",
    "    nfl = requests.get('https://sportsbook.fanduel.com/cache/psmg/UK/57494.3.json').json()\n",
    "    nba = requests.get('https://sportsbook.fanduel.com/cache/psmg/UK/55978.3.json').json()\n",
    "    bball = requests.get('https://sportsbook.fanduel.com/cache/psmg/US/53474.3.json').json()\n",
    "\n",
    "\n",
    "    #setting up df\n",
    "    cbb = parse_data(bball)\n",
    "    cb = pd.DataFrame()\n",
    "    cbb_ = cbb[cbb['name.markets']=='Spread Betting']\n",
    "    cb[['lines','team','away_t','home_t','start_time']] = cbb_[['currenthandicap.selections','name.selections','participantname_away','participantname_home','tsstart']]\n",
    "\n",
    "    away = cb[cb['team']==cb['away_t']]\n",
    "    away['lines'] = away['lines'].astype(int)*-1\n",
    "    home = cb[cb['team']==cb['home_t']]\n",
    "\n",
    "    away = pd.merge(away,away_initial,on='team')\n",
    "    home = pd.merge(home,home_initial,on='team')\n",
    "    home['difference'] = home['initial_lines'].astype(int) - home['lines'].astype(int)\n",
    "    away['difference'] = away['initial_lines'].astype(int) - away['lines'].astype(int)\n",
    "    pieces = (away,home)\n",
    "    all_games_today = pd.concat(pieces, ignore_index = True)\n",
    "    all_games_today = all_games_today[all_games_today['start_time']>='2022-01-26T19:50:00']\n",
    "\n",
    "    now = datetime.now()\n",
    "    all_games_today['current_time'] = now\n",
    "    all_games_today['datethen'] = pd.to_datetime(all_games_today['current_time'],infer_datetime_format = True)\n",
    "    all_games_today['start_time'] = pd.to_datetime(all_games_today['start_time'],infer_datetime_format = True)\n",
    "    all_games_today['time_from_start'] = all_games_today['datethen']-all_games_today['start_time']\n",
    "\n",
    "    all_games_today = all_games_today.sort_values('difference')\n",
    "\n",
    "    all_games_today['rank'] = all_games_today['difference']\n",
    "    all_games_today = all_games_today.set_index('rank')\n",
    "    return all_games_today       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'name': 'All Splits',\n",
       "   'abbreviation': 'Any',\n",
       "   'type': 'total',\n",
       "   'summary': '10-7'},\n",
       "  {'name': 'Home', 'type': 'home', 'summary': '5-4'},\n",
       "  {'name': 'Road', 'type': 'road', 'summary': '5-3'}],\n",
       " [{'name': 'All Splits',\n",
       "   'abbreviation': 'Any',\n",
       "   'type': 'total',\n",
       "   'summary': '12-5'},\n",
       "  {'name': 'Home', 'type': 'home', 'summary': '5-3'},\n",
       "  {'name': 'Road', 'type': 'road', 'summary': '7-2'}]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superbowl = 'http://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard'\n",
    "import requests as re\n",
    "df = re.get(superbowl).json()\n",
    "df = df['events']\n",
    "for s in df:\n",
    "    df = s['competitions']\n",
    "aa = {'a':[]}\n",
    "for d in df:\n",
    "    aa['a'].append(d['competitors'])\n",
    "df = aa['a']\n",
    "\n",
    "aa = {'a':[]}\n",
    "for d in df1:\n",
    "    aa['a'].append(d['records'])\n",
    "df = aa['a']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>stats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sony Michel</td>\n",
       "      <td>RB</td>\n",
       "      <td>208 CAR, 845 YDS, 4 TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cooper Kupp</td>\n",
       "      <td>WR</td>\n",
       "      <td>145 REC, 1947 YDS, 16 TD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name position                     stats\n",
       "0  Sony Michel       RB    208 CAR, 845 YDS, 4 TD\n",
       "1  Cooper Kupp       WR  145 REC, 1947 YDS, 16 TD"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superbowl = 'http://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard'\n",
    "import requests as re\n",
    "df = re.get(superbowl).json()\n",
    "df = df['events']\n",
    "for s in df:\n",
    "    df = s['competitions']\n",
    "aa = {'a':[]}\n",
    "for d in df:\n",
    "    aa['a'].append(d['competitors'])\n",
    "df = aa['a']\n",
    "\n",
    "aa = {'a':[]}\n",
    "for d in df1:\n",
    "    aa['a'].append(d['leaders'])\n",
    "df = aa['a']\n",
    "\n",
    "away = df[1]\n",
    "home = df[0]\n",
    "\n",
    "\n",
    "away_stats ={'name':[],'position':[],'stats':[]}\n",
    "\n",
    "away_qb = away[0]\n",
    "away_rush = away[1]\n",
    "away_rush = away_rush['leaders']\n",
    "for s in away_rush:\n",
    "    away_stats['stats'].append(s['displayValue'])\n",
    "    away_rush = s['athlete']\n",
    "    away_stats['name'].append(away_rush['fullName'])\n",
    "    away_rush = away_rush['position']\n",
    "    away_stats['position'].append(away_rush['abbreviation'])\n",
    "\n",
    "away_recep = away[2]\n",
    "away_recep = away_recep['leaders']\n",
    "\n",
    "for s in away_recep:\n",
    "    away_stats['stats'].append(s['displayValue'])\n",
    "    away_recep = s['athlete']\n",
    "    away_stats['name'].append(away_recep['fullName'])\n",
    "    away_recep = away_recep['position']\n",
    "    away_stats['position'].append(away_recep['abbreviation'])\n",
    "\n",
    "away_stats = pd.DataFrame(away_stats)\n",
    "away_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iefgYLgWcVhn"
   },
   "outputs": [],
   "source": [
    "espn_scoreboard = 'http://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard'\n",
    "def moreStats(df):\n",
    "    for s in df:\n",
    "        df = s['competitors']\n",
    "    \n",
    "    a = {'a' :[]}\n",
    "    for name in df:\n",
    "        a['a'].append(name['team'])\n",
    "\n",
    "\n",
    "\n",
    "    df_0 = df[0]\n",
    "    df_0_name = a['a'][0]['displayName']\n",
    "    df_1 = df[1]\n",
    "    df_1_name = a['a'][1]['displayName']\n",
    "\n",
    "\n",
    "    df_0 = df_0['statistics']\n",
    "    df_1 = df_1['statistics']\n",
    "\n",
    "\n",
    "    team_1 = {'name':[],'value':[]}\n",
    "    team_2 = {'name':[],'value':[]}\n",
    "\n",
    "\n",
    "\n",
    "    for s in df_0:\n",
    "        team_1['name'].append(s['name'])\n",
    "        team_1['value'].append(s['displayValue'])\n",
    "\n",
    "    team_1 = pd.DataFrame(team_1)\n",
    "\n",
    "    for s in df_1:\n",
    "        team_2['name'].append(s['name'])\n",
    "        team_2['value'].append(s['displayValue'])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    team_2 = pd.DataFrame(team_2)\n",
    "    teams = pd.merge(team_1,team_2, on = 'name')\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[df_0_name] = teams['value_x']\n",
    "    df[df_1_name] = teams['value_y']\n",
    "    df['stat'] = teams['name']\n",
    "    return df\n",
    "\n",
    "def live_stats(espn_scoreboard):    \n",
    "    import requests as re\n",
    "    df = re.get(espn_scoreboard).json()\n",
    "    df = df['events']\n",
    "    dff= {'a':[]}\n",
    "    for s in df:\n",
    "        dff['a'].append(s['competitions'])\n",
    "    df = dff['a']\n",
    "    dfff = {'first':[],'second':[],'third':[],'fourth':[],'fifth':[],'sixth':[],'seventh':[],'eighth':[],'ninth':[]}\n",
    "    for nine in df:\n",
    "        dfff['first'].append(df[0])\n",
    "        dfff['second'].append(df[1])\n",
    "        dfff['third'].append(df[2])\n",
    "        dfff['fourth'].append(df[3])\n",
    "        dfff['fifth'].append(df[4])\n",
    "        dfff['sixth'].append(df[5])\n",
    "        #dfff['seventh'].append(df[6])\n",
    "        #dfff['eighth'].append(df[7])\n",
    "        #dfff['ninth'].append(df[8])\n",
    "\n",
    "\n",
    "    first = moreStats(dfff['first'][0])\n",
    "    first1 = moreStats(dfff['second'][0])\n",
    "    first2 = moreStats(dfff['third'][0])\n",
    "    first3 = moreStats(dfff['fourth'][0])\n",
    "    first4 = moreStats(dfff['fifth'][0])\n",
    "    first5 = moreStats(dfff['sixth'][0])\n",
    "    #first6 = moreStats(dfff['seventh'][0])\n",
    "    #first7 = moreStats(dfff['eighth'][0])\n",
    "    #first8 = moreStats(dfff['ninth'][0])\n",
    "\n",
    "\n",
    "    smu_v_houston = first\n",
    "    rutgers_v_ohioState = first1\n",
    "    setonHall_v_Xavier = first2\n",
    "    kansasState_v_Baylor = first3\n",
    "    oklahoma_v_texasTech= first4\n",
    "    mississippiState_v_tennessee = first5\n",
    "    \n",
    "    all_games = pd.merge( smu_v_houston, rutgers_v_ohioState,on = 'stat')\n",
    "    all_games = pd.merge(all_games ,setonHall_v_Xavier ,on = 'stat')\n",
    "    all_games = pd.merge(all_games , kansasState_v_Baylor, on = 'stat')\n",
    "    all_games = pd.merge( all_games, oklahoma_v_texasTech, on = 'stat')\n",
    "    all_games = pd.merge( all_games,mississippiState_v_tennessee ,on = 'stat')\n",
    "\n",
    "\n",
    "    all_games = all_games.set_index('stat')\n",
    "\n",
    "    \n",
    "    return all_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zZzA2q35fXO7"
   },
   "outputs": [],
   "source": [
    "def name(espn):\n",
    "    df = re.get(espn).json()\n",
    "    df = df['sports']\n",
    "    newusers = dict()\n",
    "    for ud in df:\n",
    "        newusers[ud.pop('id')] = ud\n",
    "    dd = newusers['40']\n",
    "    newnew = dict()\n",
    "    new = dd['leagues']\n",
    "    for xx in new:\n",
    "        new = xx['teams']\n",
    "    aa = {0 :[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[],10:[],11:[],12:[],13:[],14:[],15:[],16:[]}\n",
    "    nn = {'name':[]}\n",
    "    for i in range(len(new)):\n",
    "        newnew = new[i]\n",
    "        nw = newnew['team']\n",
    "        nn['name'].append(nw['displayName'])\n",
    "    nn = nn['name']\n",
    "    return nn\n",
    "\n",
    "def pre_game_stats(espn):\n",
    "    df = re.get(espn).json()\n",
    "    df = df['sports']\n",
    "    newusers = dict()\n",
    "    for ud in df:\n",
    "        newusers[ud.pop('id')] = ud\n",
    "    dd = newusers['40']\n",
    "    newnew = dict()\n",
    "    new = dd['leagues']\n",
    "    for xx in new:\n",
    "        new = xx['teams']\n",
    "    aa = {0 :[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[],10:[],11:[],12:[],13:[],14:[],15:[],16:[]}\n",
    "    for i in range(len(new)):\n",
    "        newnew = new[i]\n",
    "        nw = newnew['team']\n",
    "        nww = nw['record']\n",
    "        nwww = nww['items']\n",
    "        for summ in nwww:\n",
    "            nwww = summ['stats']\n",
    "        nwww = pd.DataFrame(nwww)\n",
    "        aa[i].append(nwww['value'])\n",
    "    a1 = pd.DataFrame(aa[0])\n",
    "    a2= pd.DataFrame(aa[1])\n",
    "    a3= pd.DataFrame(aa[2])\n",
    "    a4= pd.DataFrame(aa[3])\n",
    "    a5= pd.DataFrame(aa[4])\n",
    "    a6= pd.DataFrame(aa[5])\n",
    "    a7= pd.DataFrame(aa[6])\n",
    "    a8= pd.DataFrame(aa[7])\n",
    "    a9= pd.DataFrame(aa[8])\n",
    "    a10= pd.DataFrame(aa[9])\n",
    "    a11= pd.DataFrame(aa[10])\n",
    "    a12= pd.DataFrame(aa[11])\n",
    "    a13= pd.DataFrame(aa[12])\n",
    "    a14= pd.DataFrame(aa[13])\n",
    "    a15= pd.DataFrame(aa[14])\n",
    "    a16= pd.DataFrame(aa[15])\n",
    "    a17= pd.DataFrame(aa[16])\n",
    "    p = (a1,a2, a3 ,a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15, a16, a17)\n",
    "    a = pd.concat(p, ignore_index = True)\n",
    "    aaa = pd.DataFrame()\n",
    "    aaa['name'] = nn\n",
    "    aaa['playoffSeed'] = a[0]\n",
    "    aaa['wins'] = a[1]\n",
    "    aaa['losses'] = a[2]\n",
    "    aaa['winPercent'] = a[3]\n",
    "    aaa['gamesBehind'] = a[4]\n",
    "    aaa['ties'] = a[5]\n",
    "    aaa['OTWins'] = a[6]\n",
    "    aaa['OTLosses'] = a[7]\n",
    "    aaa['gamesPlayed'] = a[8]\n",
    "    aaa['pointsFor'] = a[9]\n",
    "    aaa['pointsAgainst'] = a[10]\n",
    "    aaa['avgPointsFor'] = a[11]\n",
    "    aaa['avgPointsAgainst'] = a[12]\n",
    "    aaa['points'] = a[13]\n",
    "    aaa['differential'] = a[14]\n",
    "    aaa['streak'] = a[15]\n",
    "    aaa['divisionWinPercent'] = a[16]\n",
    "    aaa['leagueWinPercent'] = a[17]\n",
    "    return aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_ZpG1GLmhSV2"
   },
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "import time\n",
    "time_mins = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxdXXYuPcpzX",
    "outputId": "cd5cff1c-ae66-409c-d0d9-db1d1ad092e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(time_mins):\n",
    "  glines = game_lines(time_mins)\n",
    "  glines.to_csv(f'NCAAB_GAMES_Feb13.csv',index = True)\n",
    "  time.sleep(random.uniform(60,300\n",
    "                            ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "BVtRESH0cp5_"
   },
   "outputs": [],
   "source": [
    "for i in range(time_mins):\n",
    "  all_games = live_stats(espn_scoreboard)\n",
    "  all_games.to_csv(f'{PATH}all_games.csv',index = False)\n",
    "  time.sleep(random.uniform(10,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "bLDA709wfYvN"
   },
   "outputs": [],
   "source": [
    "espn = 'http://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/teams'\n",
    "\n",
    "for i in range(time_mins):\n",
    "  nn = name(espn)\n",
    "  pregame = pre_game_stats(espn)\n",
    "  pregame.to_csv(f'{PATH}pregame_stats.csv',index = False)\n",
    "  time.sleep(random.uniform(10,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qmi1IotRfx31"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "74NHisLSfx7I"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'events'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9160ee97f514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#setting up df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbball\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mcbb_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcbb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name.markets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Spread Betting'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lines'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'team'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'away_t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'home_t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'start_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbb_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'currenthandicap.selections'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'name.selections'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'participantname_away'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'participantname_home'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tsstart'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ae03be41a8e4>\u001b[0m in \u001b[0;36mparse_data\u001b[0;34m(jsooooon)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsooooon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mayo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjsooooon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'events'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mmoney\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mayo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'markets'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbandos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mayo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'markets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'events'"
     ]
    }
   ],
   "source": [
    "#enter this to run it\n",
    "current_time = list()\n",
    "cb = pd.DataFrame()\n",
    "\n",
    "for i in range(time_mins):\n",
    "    i = [i]\n",
    "    nfl = requests.get('https://sportsbook.fanduel.com/cache/psmg/UK/57494.3.json').json()\n",
    "    nba = requests.get('https://sportsbook.fanduel.com/cache/psmg/UK/55978.3.json').json()\n",
    "    bball = requests.get('https://sportsbook.fanduel.com/cache/psmg/US/53474.3.json').json()\n",
    "\n",
    "\n",
    "    #setting up df\n",
    "    cbb = parse_data(bball)\n",
    "    cbb_ = cbb[cbb['name.markets']=='Spread Betting']\n",
    "    cb[['lines'+str(i),'team','away_t','home_t','start_time']] = cbb_[['currenthandicap.selections','name.selections','participantname_away','participantname_home','tsstart']]\n",
    "\n",
    "    away = cb[cb['team']==cb['away_t']]\n",
    "    away['lines'+str(i)] = away['lines'+str(i)].astype(int)*-1\n",
    "    home = cb[cb['team']==cb['home_t']]\n",
    "\n",
    "    away = pd.merge(away,away_initial,on='team')\n",
    "    home = pd.merge(home,home_initial,on='team')\n",
    "    home['difference'] = home['initial_lines'].astype(int) - home['lines'+str(i)].astype(int)\n",
    "    away['difference'] = away['initial_lines'].astype(int) - away['lines'+str(i)].astype(int)\n",
    "    pieces = (away,home)\n",
    "    all_games_today = pd.concat(pieces, ignore_index = True)\n",
    "    all_games_today = all_games_today[all_games_today['start_time']>='2022-01-25T15:20:00']\n",
    "    \n",
    "    now = datetime.now()\n",
    "    all_games_today['current_time'] = now\n",
    "    all_games_today['datethen'] = pd.to_datetime(all_games_today['current_time'],infer_datetime_format = True)\n",
    "    all_games_today['start_time'] = pd.to_datetime(all_games_today['start_time'],infer_datetime_format = True)\n",
    "    all_games_today['time_from_start'] = all_games_today['datethen']-all_games_today['start_time']\n",
    "    \n",
    "    all_games_today_away = all_games_today[all_games_today['team']==all_games_today['away_t']]\n",
    "    all_games_today_home = all_games_today[all_games_today['team']==all_games_today['home_t']]\n",
    "\n",
    "    all_games_today_away = all_games_today_away.sort_values('difference')\n",
    "    all_games_today_home = all_games_today_home.sort_values('difference')\n",
    "\n",
    "    \n",
    "    if len(all_games_today_home)>3:\n",
    "        all_games_today_home.to_csv('NCAAB_HOMEGAMES_FEB9.csv',index = False)\n",
    "    if len(all_games_today_away)>3:\n",
    "        all_games_today_away.to_csv('NCAAB_AWAYGAMES_FEB9.csv',index = False)\n",
    "\n",
    "    time.sleep(random.uniform(60,120))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RUywg4Lfx-i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pL5vWl19fYxv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LtnYGwIksau"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "_4P8ymYldhyZ"
   },
   "outputs": [],
   "source": [
    "import requests as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKQve_HafcaA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of Copy of new_sep_filtered_NCAAB_LIVE_ODDS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
